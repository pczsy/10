<html><head><meta charset='utf-8'><meta name='viewport' content='width=device-width, initial-scale=1'>
<meta name='applicable-device' content='pc'><meta name='keywords' content='电脑,电脑讲解,电脑技术,编程,电脑故障维修Scrapy框架的简单使用' />
<script src='../../highlight/highlight.pack.js'></script>
<link rel='stylesheet' type='text/css' href='../../highlight/styles/monokai.css'/>

<link rel='stylesheet' href='../../fenxiang/dist/css/share.min.css'>
<script src='../../fenxiang/src/js/social-share.js'></script>
<script src='../../fenxiang/src/js/qrcode.js'></script>

</head><body><script>hljs.initHighlightingOnLoad();</script><script>
var system ={};  
var p = navigator.platform;       
system.win = p.indexOf('Win') == 0;  
system.mac = p.indexOf('Mac') == 0;  
system.x11 = (p == 'X11') || (p.indexOf('Linux') == 0);     
if(system.win||system.mac||system.xll){
document.write("<link href='../css/3.css' rel='stylesheet' type='text/css'>");}else{ document.write("<link href='../css/3wap.css' rel='stylesheet' type='text/css'>");}</script><script src='../../js/3.js'></script><div class='div2'><div class='heading_nav'><ul><div><li><a href='../../index.html'>首页</a></li>
</div><div onclick='hidden1()' >分享</div>
</ul></div></div>
<div id='heading_nav2'> 
<li class='row' >
<div class='social-share' data-mode='prepend'><a href='javascript:' class='social-share-icon icon-heart'></a></div></li></div><script charset='utf-8' src='../../3/js/hengfu.js'></script><script charset='utf-8' src='../../3/js/hengfu2.js'></script><hr><div class='div1'><div class='biaoti'><center>Scrapy框架的简单使用</center></div><div class='banquan'>原文出处:本文由博客园博主小小咸鱼YwY提供。<br/>
原文连接:https://www.cnblogs.com/pythonywy/p/11719790.html</div><br>
    <h2 id="一.安装依赖">一.安装依赖</h2>
<pre><code><code>#Windows平台
    1、pip3 install wheel
    3、pip3 install lxml
    4、pip3 install pyopenssl
    5、pip3 install pywin32  #如果不行去官网https://sourceforge.net/projects/pywin32/files/pywin32/
    6、pip3 install twisted #如果不行去官网：http://www.lfd.uci.edu/~gohlke/pythonlibs/#twisted
    7、pip3 install scrapy
  
#Linux平台
    1、pip3 install scrapy</code></pre>
<h2 id="二.命令">二.命令</h2>
<pre><code><code>#1 查看帮助
    scrapy -h
    scrapy &lt;command&gt; -h

#2 有两种命令：其中Project-only必须切到项目文件夹下才能执行，而Global的命令则不需要
    Global commands:
        startproject #创建项目
        genspider    #基本上都要cd项目目录,scrapy genspider 名称 url
        settings     #如果是在项目目录下，则得到的是该项目的配置
        runspider    #运行一个独立的python文件，不必创建项目
        shell        #scrapy shell url地址  在交互式调试，如选择器规则正确与否
        fetch        #独立于程单纯地爬取一个页面，可以拿到请求头
        view         #下载完毕后直接弹出浏览器，以此可以分辨出哪些数据是ajax请求
        version      #scrapy version 查看scrapy的版本，scrapy version -v查看scrapy依赖库的版本
    Project-only commands:
        crawl        #运行爬虫，必须创建项目才行，确保配置文件中ROBOTSTXT_OBEY = False
        check        #检测项目中有无语法错误
        list         #列出项目中所包含的爬虫名
        edit         #编辑器，一般不用
        parse        #scrapy parse url地址 --callback 回调函数  #以此可以验证我们的回调函数是否正确
        bench        #scrapy bentch压力测试

#3 官网链接
    https://docs.scrapy.org/en/latest/topics/commands.html</code></pre>
<p><code>crawl</code>运行爬虫程序如果不打印日志</p>
<p><code>scrapy crawl 爬虫程序中的name --nolog</code></p>
<h2 id="三.文件说明">三.文件说明</h2>
<ul>
<li>scrapy.cfg 项目的主配置信息，用来部署scrapy时使用，爬虫相关的配置信息在settings.py文件中。</li>
<li>items.py 设置数据存储模板，用于结构化数据，如：Django的Model</li>
<li>pipelines 数据处理行为，如：一般结构化的数据持久化</li>
<li>settings.py 配置文件，如：递归的层数、并发数，延迟下载等。<strong>强调:配置文件的选项必须大写否则视为无效，正确写法USER_AGENT='xxxx'</strong></li>
<li>spiders 爬虫目录，如：创建文件，编写爬虫规则</li>
</ul>

</div>
</div><hr><script charset='utf-8' src='../../js/sming.js'></script></body></html>