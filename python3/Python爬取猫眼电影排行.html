<html><head><meta charset='utf-8'><meta name='viewport' content='width=device-width, initial-scale=1'>
<meta name='applicable-device' content='pc'><meta name='keywords' content='电脑,电脑讲解,电脑技术,编程,电脑故障维修Python爬取猫眼电影排行' />
<script src='../../highlight/highlight.pack.js'></script>
<link rel='stylesheet' type='text/css' href='../../highlight/styles/monokai.css'/>

<link rel='stylesheet' href='../../fenxiang/dist/css/share.min.css'>
<script src='../../fenxiang/src/js/social-share.js'></script>
<script src='../../fenxiang/src/js/qrcode.js'></script>

</head><body><script>hljs.initHighlightingOnLoad();</script><script>
var system ={};  
var p = navigator.platform;       
system.win = p.indexOf('Win') == 0;  
system.mac = p.indexOf('Mac') == 0;  
system.x11 = (p == 'X11') || (p.indexOf('Linux') == 0);     
if(system.win||system.mac||system.xll){
document.write("<link href='../css/3.css' rel='stylesheet' type='text/css'>");}else{ document.write("<link href='../css/3wap.css' rel='stylesheet' type='text/css'>");}</script><script src='../../js/3.js'></script><div class='div2'><div class='heading_nav'><ul><div><li><a href='../../index.html'>首页</a></li>
</div><div onclick='hidden1()' >分享</div>
</ul></div></div>
<div id='heading_nav2'> 
<li class='row' >
<div class='social-share' data-mode='prepend'><a href='javascript:' class='social-share-icon icon-heart'></a></div></li></div><script charset='utf-8' src='../../3/js/hengfu.js'></script><script charset='utf-8' src='../../3/js/hengfu2.js'></script><hr><div class='div1'><div class='biaoti'><center>Python爬取猫眼电影排行</center></div><div class='banquan'>原文出处:本文由博客园博主__风提供。<br/>
原文连接:https://www.cnblogs.com/malinqing/p/11318341.html</div><br>
    <pre><code><code>import requests
import pyquery


def crawl_page(url: str) -&gt; None:
    headers = {
        &#39;user-agent&#39;: &#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) \
Chrome/72.0.3626.121 Safari/537.36&#39;,
    }
    response = requests.get(url, headers=headers)
    parse_page(response.text)


def parse_page(source_code: str) -&gt; None:
    html = pyquery.PyQuery(source_code)
    dd_elements = html(&#39;.board-wrapper dd&#39;)
    for dd_element in dd_elements.items():
        data = {
            &#39;排名&#39;: dd_element.find(&#39;i.board-index&#39;).text(),
            &#39;电影名&#39;: dd_element.find(&#39;a.image-link&#39;).attr(&#39;title&#39;),
            &#39;主演&#39;: dd_element.find(&#39;p.star&#39;).text().split(&#39;：&#39;)[1],
            &#39;上映时间&#39;: dd_element.find(&#39;p.releasetime&#39;).text().split(&#39;：&#39;)[1],
            &#39;评分&#39;: dd_element.find(&#39;p.score&#39;).text(),
        }
        print(data)
        save_data(data)


def save_data(data: dict) -&gt; None:
    data = str(data)
    with open(&#39;MaoYan.txt&#39;, &#39;a+&#39;, encoding=&#39;utf8&#39;) as f:
        f.write(data+&#39;\n&#39;)
    return None


def main():
    for i in range(0, 100, 10):
        url = &#39;https://maoyan.com/board/4?offset={}&#39;.format(i)
        crawl_page(url)


if __name__ == &#39;__main__&#39;:
    main()</code></pre>

</div>
</div><hr><script charset='utf-8' src='../../js/sming.js'></script></body></html>