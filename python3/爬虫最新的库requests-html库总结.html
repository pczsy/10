<html><head><meta charset='utf-8'><meta name='viewport' content='width=device-width, initial-scale=1'>
<meta name='applicable-device' content='pc'><meta name='keywords' content='电脑,电脑讲解,电脑技术,编程,电脑故障维修爬虫最新的库requests-html库总结' />
<script src='../../highlight/highlight.pack.js'></script>
<link rel='stylesheet' type='text/css' href='../../highlight/styles/monokai.css'/>

<link rel='stylesheet' href='../../fenxiang/dist/css/share.min.css'>
<script src='../../fenxiang/src/js/social-share.js'></script>
<script src='../../fenxiang/src/js/qrcode.js'></script>

</head><body><script>hljs.initHighlightingOnLoad();</script><script>
var system ={};  
var p = navigator.platform;       
system.win = p.indexOf('Win') == 0;  
system.mac = p.indexOf('Mac') == 0;  
system.x11 = (p == 'X11') || (p.indexOf('Linux') == 0);     
if(system.win||system.mac||system.xll){
document.write("<link href='../css/3.css' rel='stylesheet' type='text/css'>");}else{ document.write("<link href='../css/3wap.css' rel='stylesheet' type='text/css'>");}</script><script src='../../js/3.js'></script><div class='div2'><div class='heading_nav'><ul><div><li><a href='../../index.html'>首页</a></li>
</div><div onclick='hidden1()' >分享</div>
</ul></div></div>
<div id='heading_nav2'> 
<li class='row' >
<div class='social-share' data-mode='prepend'><a href='javascript:' class='social-share-icon icon-heart'></a></div></li></div><script charset='utf-8' src='../../3/js/hengfu.js'></script><script charset='utf-8' src='../../3/js/hengfu2.js'></script><hr><div class='div1'><div class='biaoti'><center>爬虫最新的库requests-html库总结</center></div><div class='banquan'>原文出处:本文由博客园博主小小咸鱼YwY提供。<br/>
原文连接:https://www.cnblogs.com/pythonywy/p/11693178.html</div><br>
    <p><code>requests-html是比较新的爬虫库,作者和requests是同一个作者</code></p>
<h2 id="一.安装依赖">一.安装依赖</h2>
<p><code>pip install requests-html</code></p>
<p>我们可以在安装的时候看到他安装了lxml,reuqests,bs4......我们常用的解析和爬取的库都分装在他里面</p>
<h2 id="二.-发起请求">二. 发起请求</h2>
<pre><code><code>from requests_html import HTMLSession
session = HTMLSession()

#用法和requests.session实例化的对象用法一模一样,也会自动保存返回信息
#相比reuqests,他多了对于response.html这个属性</code></pre>
<p><code>注意点</code>:发默认发送的的是<code>无头浏览器</code>,且他如果用render<code>调用浏览器内核</code></p>
<h3 id="解决无头浏览器针对反爬如果没有做反爬无所谓">1.解决无头浏览器(针对反爬,如果没有做反爬无所谓)</h3>
<p><code>修改源码</code></p>
<ul>
<li><p>ctrl左键进入<code>HTMLSession</code></p></li>
<li><p>我们可以看到他是继承<code>BaseSession</code></p></li>
<li><p>ctrl左键进入<code>BaseSession</code></p>
<p><code>原来的源码</code></p>
<pre><code><code>class BaseSession(requests.Session):
    def __init__(self, mock_browser : bool = True, verify : bool = True,
                 browser_args : list = [&#39;--no-sandbox&#39;]):
        super().__init__()
        if mock_browser:
        self.headers[&#39;User-Agent&#39;] = user_agent()

        self.hooks[&#39;response&#39;].append(self.response_hook)
        self.verify = verify

        self.__browser_args = browser_args
        self.__headless = headless

      #中间没用的省略掉不是删掉
    @property
    async def browser(self):
        if not hasattr(self, &quot;_browser&quot;):
            self._browser = await pyppeteer.launch(ignoreHTTPSErrors=not(self.verify), headless=True, args=self.__browser_args)

        return self._browser</code></pre>
<p><code>修改后的源码</code></p>
<pre><code><code>class BaseSession(requests.Session):
    &quot;&quot;&quot; A consumable session, for cookie persistence and connection pooling,
    amongst other things.
    &quot;&quot;&quot;

    def __init__(self, mock_browser : bool = True, verify : bool = True,
                 browser_args : list = [&#39;--no-sandbox&#39;],headless=False):       #如果你设置成True他就是无头,且你再运行render时候不会弹出浏览器
        super().__init__()

        # Mock a web browser&#39;s user agent.
        if mock_browser:
            self.headers[&#39;User-Agent&#39;] = user_agent()

        self.hooks[&#39;response&#39;].append(self.response_hook)
        self.verify = verify

        self.__browser_args = browser_args
        self.__headless = headless
          #中间没用的省略掉不是删掉
    @property
    async def browser(self):
        if not hasattr(self, &quot;_browser&quot;):
            self._browser = await pyppeteer.launch(ignoreHTTPSErrors=not(self.verify), headless=self.__headless, args=self.__browser_args)

        return self._browser</code></pre>
<p><code>其实我就做了个处理方便传一个headless进去</code></p></li>
</ul>
<p>对于<code>session</code>重新设置</p>
<pre><code><code>from requests_html import HTMLSession
session = HTMLSession(
browser_args=[&#39;--no-sand&#39;,
              &#39;--user-agent=&#39;xxxxx&#39;
             ]
)
#这样你就可以直接定义他是什么浏览器发送请求啦</code></pre>
<h3 id="解决浏览器内核针对反爬如果没有做反爬无所谓">2.解决浏览器内核(针对反爬,如果没有做反爬无所谓)</h3>
<pre><code><code>#利用模块进行js注入
from requests_html  import HTMLSession

session  =HTMLSession(.....)
response = session.get(&#39;https://www.baidu.com&#39;)
script=&#39;&#39;&#39;
()=&gt;{
Object.defineProperties(navigator,{
        webdriver:{
        get: () =&gt; undefined
        }
    })}&#39;&#39;&#39;
print(response.html.render(script=script))</code></pre>
<h2 id="三.response.html相关属性">三.response.html相关属性</h2>
<p>这里的response对象是</p>
<pre><code><code>from requests_html  import HTMLSession
session  =HTMLSession()
response = session.get(&#39;https://www.baidu.com&#39;)
#为了大家好理解就这个response</code></pre>
<h3 id="absolute_links">1.absolute_links</h3>
<p>所有的路径都会转成<code>绝对路径</code>返回</p>
<h3 id="links">2.links</h3>
<p><code>返还路径原样</code></p>
<h3 id="base_url">3.base_url</h3>
<p>.base标签里的路径,如果没有base标签,就是当前url</p>
<h3 id="html">4.html</h3>
<p>返回字符串字符串内包含有标签</p>
<h3 id="text">5.text</h3>
<p>返回字符串字符串内不包含有标签<code>爬取什么小说新闻之类的超级好用!</code></p>
<h3 id="encoding">6.encoding</h3>
<p>解码格式,注意这里是response.html的encoding,你如果只只设置了response.encoding对这个encoding毫无影响</p>
<h3 id="raw_html">7.raw_html</h3>
<p><code>相当于r.content</code>返回二进制</p>
<h3 id="pq">8.pq</h3>
<p>返回PyQuery对象,个人不怎么用这个库所有不写结论</p>
<h2 id="四.response.html相关方法">四.response.html相关方法</h2>
<p>下面response对象我就简写成 r了</p>
<h3 id="find">1.find</h3>
<p>用css选择器找对象</p>
<p><code>获取全部</code></p>
<p><code>语法</code>:r.html.find('css选择器')</p>
<p><code>返回值</code>:[element对象1，。。。。。] <code>是个列表</code></p>
<p><code>只获取第一个</code></p>
<p>语法`:r.html.find('css选择器',first = True)</p>
<p><code>返回值</code>:element对象</p>
<h3 id="xpath">2.xpath</h3>
<p>用xpath选择器找对象</p>
<p><code>获取全部</code></p>
<p><code>语法</code>:r.html.xpath('xpath选择器')</p>
<p><code>返回值</code>:[Element对象1，。。。。。] <code>是列表</code></p>
<p><code>只获取第一个</code></p>
<p>语法`:r.html.xpath('xpath选择器',first = True)</p>
<p><code>返回值</code>:Element对象</p>
<h3 id="search只获取第一个">3.search(只获取第一个)</h3>
<p>类似用正则匹配,就是把正则里面的<code>(.*?)</code>变成<code>{}</code></p>
<p><code>语法</code>:r.html.search(‘模板’)</p>
<p>模板一:('xx{}xxx{}')</p>
<p>获取:<code>获取第一个</code>:r.html.search(‘模板’)[0]<code>其他以此类推</code></p>
<p>模板二:（‘xxx{name}yyy{pwd}’）</p>
<p>获取:<code>获取第一个</code>:r.html.search(‘模板’)['name']<code>其他以此类推</code></p>
<h3 id="search_all获取全部">4.search_all(获取全部)</h3>
<p>用法和search一样</p>
<p>返回值: 【result对象，result对象，】</p>
<h3 id="render这个我后续单独写一个总结内容有点多">5.render(这个我后续单独写一个总结内容有点多)</h3>
<p>他其实就是封装了<code>pyppeteer</code>你如果不了解<code>pyppeteer</code>,那可以想想<code>Selenium</code>就是模拟浏览器访问</p>
<h2 id="五.element对象方法及属性">五.Element对象方法及属性</h2>
<ul>
<li>absolute_links:绝对url</li>
<li>links:相对url</li>
<li>text:只显示文本</li>
<li>html:标签也会显示</li>
<li>attrs:属性</li>
<li>find('css选择器')</li>
<li>xpath('xapth路径')</li>
<li>.search('模板')</li>
<li>.search_all('模板')</li>
</ul>

</div>
</div><hr><script charset='utf-8' src='../../js/sming.js'></script></body></html>