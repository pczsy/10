<html><head><meta charset='utf-8'><meta name='viewport' content='width=device-width, initial-scale=1'>
<meta name='applicable-device' content='pc'><meta name='keywords' content='电脑,电脑讲解,电脑技术,编程,电脑故障维修scrapy框架爬取智联招聘网站上深圳地区python岗位信息。' />
<script src='../../highlight/highlight.pack.js'></script>
<link rel='stylesheet' type='text/css' href='../../highlight/styles/monokai.css'/>

<link rel='stylesheet' href='../../fenxiang/dist/css/share.min.css'>
<script src='../../fenxiang/src/js/social-share.js'></script>
<script src='../../fenxiang/src/js/qrcode.js'></script>

</head><body><script>hljs.initHighlightingOnLoad();</script><script>
var system ={};  
var p = navigator.platform;       
system.win = p.indexOf('Win') == 0;  
system.mac = p.indexOf('Mac') == 0;  
system.x11 = (p == 'X11') || (p.indexOf('Linux') == 0);     
if(system.win||system.mac||system.xll){
document.write("<link href='../css/3.css' rel='stylesheet' type='text/css'>");}else{ document.write("<link href='../css/3wap.css' rel='stylesheet' type='text/css'>");}</script><script src='../../js/3.js'></script><div class='div2'><div class='heading_nav'><ul><div><li><a href='../../index.html'>首页</a></li>
</div><div onclick='hidden1()' >分享</div>
</ul></div></div>
<div id='heading_nav2'> 
<li class='row' >
<div class='social-share' data-mode='prepend'><a href='javascript:' class='social-share-icon icon-heart'></a></div></li></div><script charset='utf-8' src='../../3/js/hengfu.js'></script><script charset='utf-8' src='../../3/js/hengfu2.js'></script><hr><div class='div1'><div class='biaoti'><center>scrapy框架爬取智联招聘网站上深圳地区python岗位信息。</center></div><div class='banquan'>原文出处:本文由博客园博主记住我忘记我提供。<br/>
原文连接:https://www.cnblogs.com/nmsghgnv/p/11348448.html</div><br>
    <p>爬取字段，公司名称，职位名称，公司详情的链接，薪资待遇，要求的工作经验年限</p>
<p>1，items中定义爬取字段</p>
<div class="cnblogs_code">
<pre><code><span style="color: #0000ff;">import</span><span style="color: #000000;"> scrapy


</span><span style="color: #0000ff;">class</span><span style="color: #000000;"> ZhilianzhaopinItem(scrapy.Item):
    </span><span style="color: #008000;">#</span><span style="color: #008000;"> define the fields for your item here like:</span>
    <span style="color: #008000;">#</span><span style="color: #008000;"> name = scrapy.Field()</span>
    company_name =<span style="color: #000000;"> scrapy.Field()
    jobName </span>=<span style="color: #000000;"> scrapy.Field()
    company_url </span>=<span style="color: #000000;"> scrapy.Field()
    salary </span>=<span style="color: #000000;"> scrapy.Field()
    workingExp </span>= scrapy.Field()</pre>
</div>
<p>2，主程序函数</p>
<div class="cnblogs_code">
<pre><code><span style="color: #008000;">#</span><span style="color: #008000;"> -*- coding: utf-8 -*-</span>
<span style="color: #0000ff;">import</span><span style="color: #000000;"> scrapy
</span><span style="color: #0000ff;">from</span> urllib.parse <span style="color: #0000ff;">import</span><span style="color: #000000;"> urlencode
</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> json
</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> math
</span><span style="color: #0000ff;">from</span> zhilianzhaopin.items <span style="color: #0000ff;">import</span><span style="color: #000000;"> ZhilianzhaopinItem
</span><span style="color: #0000ff;">class</span><span style="color: #000000;"> ZlzpSpider(scrapy.Spider):
    name </span>= <span style="color: #800000;">'</span><span style="color: #800000;">zlzp</span><span style="color: #800000;">'</span>
    <span style="color: #008000;">#</span><span style="color: #008000;"> allowed_domains = ['www.zhaopin.com']</span>
    start_urls = [<span style="color: #800000;">'</span><span style="color: #800000;">https://fe-api.zhaopin.com/c/i/sou?</span><span style="color: #800000;">'</span><span style="color: #000000;">]
    data </span>=<span style="color: #000000;"> {
        </span><span style="color: #800000;">'</span><span style="color: #800000;">start</span><span style="color: #800000;">'</span>: <span style="color: #800000;">'</span><span style="color: #800000;">0</span><span style="color: #800000;">'</span><span style="color: #000000;">,
        </span><span style="color: #800000;">'</span><span style="color: #800000;">pageSize</span><span style="color: #800000;">'</span>: <span style="color: #800000;">'</span><span style="color: #800000;">90</span><span style="color: #800000;">'</span><span style="color: #000000;">,
        </span><span style="color: #800000;">'</span><span style="color: #800000;">cityId</span><span style="color: #800000;">'</span>: <span style="color: #800000;">'</span><span style="color: #800000;">765</span><span style="color: #800000;">'</span><span style="color: #000000;">,
        </span><span style="color: #800000;">'</span><span style="color: #800000;">kw</span><span style="color: #800000;">'</span>: <span style="color: #800000;">'</span><span style="color: #800000;">python</span><span style="color: #800000;">'</span><span style="color: #000000;">,
        </span><span style="color: #800000;">'</span><span style="color: #800000;">kt</span><span style="color: #800000;">'</span>: <span style="color: #800000;">'</span><span style="color: #800000;">3</span><span style="color: #800000;">'</span><span style="color: #000000;">
    }
    </span><span style="color: #0000ff;">def</span><span style="color: #000000;"> start_requests(self):
        url </span>= self.start_urls[0]+<span style="color: #000000;">urlencode(self.data)
        </span><span style="color: #0000ff;">yield</span> scrapy.Request(url=url,callback=<span style="color: #000000;">self.parse)

    </span><span style="color: #0000ff;">def</span><span style="color: #000000;"> parse(self, response):
        response </span>=<span style="color: #000000;"> json.loads(response.text)
        sum </span>= int(response[<span style="color: #800000;">'</span><span style="color: #800000;">data</span><span style="color: #800000;">'</span>][<span style="color: #800000;">'</span><span style="color: #800000;">count</span><span style="color: #800000;">'</span><span style="color: #000000;">])
        </span><span style="color: #0000ff;">for</span> res <span style="color: #0000ff;">in</span> response[<span style="color: #800000;">'</span><span style="color: #800000;">data</span><span style="color: #800000;">'</span>][<span style="color: #800000;">'</span><span style="color: #800000;">results</span><span style="color: #800000;">'</span><span style="color: #000000;">]:
            item </span>=<span style="color: #000000;"> ZhilianzhaopinItem()
            item[</span><span style="color: #800000;">'</span><span style="color: #800000;">company_name</span><span style="color: #800000;">'</span>] = res[<span style="color: #800000;">'</span><span style="color: #800000;">company</span><span style="color: #800000;">'</span>][<span style="color: #800000;">'</span><span style="color: #800000;">name</span><span style="color: #800000;">'</span><span style="color: #000000;">]
            item[</span><span style="color: #800000;">'</span><span style="color: #800000;">jobName</span><span style="color: #800000;">'</span>] = res[<span style="color: #800000;">'</span><span style="color: #800000;">jobName</span><span style="color: #800000;">'</span><span style="color: #000000;">]
            item[</span><span style="color: #800000;">'</span><span style="color: #800000;">company_url</span><span style="color: #800000;">'</span>] = res[<span style="color: #800000;">'</span><span style="color: #800000;">company</span><span style="color: #800000;">'</span>][<span style="color: #800000;">'</span><span style="color: #800000;">url</span><span style="color: #800000;">'</span><span style="color: #000000;">]
            item[</span><span style="color: #800000;">'</span><span style="color: #800000;">salary</span><span style="color: #800000;">'</span>] = res[<span style="color: #800000;">'</span><span style="color: #800000;">salary</span><span style="color: #800000;">'</span><span style="color: #000000;">]
            item[</span><span style="color: #800000;">'</span><span style="color: #800000;">workingExp</span><span style="color: #800000;">'</span>] = res[<span style="color: #800000;">'</span><span style="color: #800000;">workingExp</span><span style="color: #800000;">'</span>][<span style="color: #800000;">'</span><span style="color: #800000;">name</span><span style="color: #800000;">'</span><span style="color: #000000;">]
            </span><span style="color: #0000ff;">yield</span><span style="color: #000000;"> item

        </span><span style="color: #0000ff;">for</span> url_info <span style="color: #0000ff;">in</span> range(90,sum,90<span style="color: #000000;">):
            self.data[</span><span style="color: #800000;">'</span><span style="color: #800000;">start</span><span style="color: #800000;">'</span>] =<span style="color: #000000;"> str(url_info)
            url_i </span>= self.start_urls[0]+<span style="color: #000000;">urlencode(self.data)
            </span><span style="color: #0000ff;">yield</span> scrapy.Request(url=url_i,callback=self.parse)</pre>
</div>
<p>3，settings中设置请求头和打开下载管道</p>
<div class="cnblogs_code">
<pre><code>USER_AGENT = <span style="color: #800000;">'</span><span style="color: #800000;">Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.71 Safari/537.36</span><span style="color: #800000;">'</span><span style="color: #000000;">

ITEM_PIPELINES </span>=<span style="color: #000000;"> {
   </span><span style="color: #800000;">'</span><span style="color: #800000;">zhilianzhaopin.pipelines.ZhilianzhaopinPipeline</span><span style="color: #800000;">'</span>: 300<span style="color: #000000;">,
}</span></pre>
</div>
<p>4，创建数据库，</p>
<p>5，pipelines.py文件中写入数据库</p>
<div class="cnblogs_code">
<pre><code><span style="color: #0000ff;">import</span><span style="color: #000000;"> pymysql
</span><span style="color: #008000;">#</span><span style="color: #008000;"> 写入mysql数据库</span>
<span style="color: #0000ff;">class</span><span style="color: #000000;"> ZhilianzhaopinPipeline(object):
    conn </span>=<span style="color: #000000;"> None
    mycursor </span>=<span style="color: #000000;"> None
    </span><span style="color: #0000ff;">def</span><span style="color: #000000;"> open_spider(self, spider):
        </span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">'</span><span style="color: #800000;">链接数据库...</span><span style="color: #800000;">'</span><span style="color: #000000;">)
        self.conn </span>= pymysql.connect(host=<span style="color: #800000;">'</span><span style="color: #800000;">172.16.25.4</span><span style="color: #800000;">'</span>, user=<span style="color: #800000;">'</span><span style="color: #800000;">root</span><span style="color: #800000;">'</span>, password=<span style="color: #800000;">'</span><span style="color: #800000;">root</span><span style="color: #800000;">'</span>, db=<span style="color: #800000;">'</span><span style="color: #800000;">scrapy</span><span style="color: #800000;">'</span><span style="color: #000000;">)
        self.mycursor </span>=<span style="color: #000000;"> self.conn.cursor()
    </span><span style="color: #0000ff;">def</span><span style="color: #000000;"> process_item(self, item, spider):
        </span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">'</span><span style="color: #800000;">正在写数据库...</span><span style="color: #800000;">'</span><span style="color: #000000;">)
        company_name </span>= item[<span style="color: #800000;">'</span><span style="color: #800000;">company_name</span><span style="color: #800000;">'</span><span style="color: #000000;">]
        jobName </span>= item[<span style="color: #800000;">'</span><span style="color: #800000;">jobName</span><span style="color: #800000;">'</span><span style="color: #000000;">]
        company_url </span>= item[<span style="color: #800000;">'</span><span style="color: #800000;">company_url</span><span style="color: #800000;">'</span><span style="color: #000000;">]
        salary </span>= item[<span style="color: #800000;">'</span><span style="color: #800000;">salary</span><span style="color: #800000;">'</span><span style="color: #000000;">]
        workingExp </span>= item[<span style="color: #800000;">'</span><span style="color: #800000;">workingExp</span><span style="color: #800000;">'</span><span style="color: #000000;">]
        sql </span>= <span style="color: #800000;">'</span><span style="color: #800000;">insert into zlzp VALUES (null,"%s","%s","%s","%s","%s")</span><span style="color: #800000;">'</span> %<span style="color: #000000;"> (company_name, jobName, company_url,salary,workingExp)
        bool </span>=<span style="color: #000000;"> self.mycursor.execute(sql)
        self.conn.commit()
        </span><span style="color: #0000ff;">return</span><span style="color: #000000;"> item

    </span><span style="color: #0000ff;">def</span><span style="color: #000000;"> close_spider(self, spider):
        </span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">'</span><span style="color: #800000;">写入数据库完成...</span><span style="color: #800000;">'</span><span style="color: #000000;">)
        self.mycursor.close()
        self.conn.close()</span></pre>
</div>
<p>6，查看是否写入成功</p>
<p><img src="./images/scrapy框架爬取智联招聘网站上深圳地区python岗位信息。0.png" alt="" /></p>
<p>done。</p>
</div>
</div><hr><script charset='utf-8' src='../../js/sming.js'></script></body></html>