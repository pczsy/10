<html><head><meta charset='utf-8'><meta name='viewport' content='width=device-width, initial-scale=1'>
<meta name='applicable-device' content='pc'><meta name='keywords' content='电脑,电脑讲解,电脑技术,编程,电脑故障维修2019基于python的网络爬虫系列，爬取糗事百科' />
<script src='../../highlight/highlight.pack.js'></script>
<link rel='stylesheet' type='text/css' href='../../highlight/styles/monokai.css'/>

<link rel='stylesheet' href='../../fenxiang/dist/css/share.min.css'>
<script src='../../fenxiang/src/js/social-share.js'></script>
<script src='../../fenxiang/src/js/qrcode.js'></script>

</head><body><script>hljs.initHighlightingOnLoad();</script><script>
var system ={};  
var p = navigator.platform;       
system.win = p.indexOf('Win') == 0;  
system.mac = p.indexOf('Mac') == 0;  
system.x11 = (p == 'X11') || (p.indexOf('Linux') == 0);     
if(system.win||system.mac||system.xll){
document.write("<link href='../css/3.css' rel='stylesheet' type='text/css'>");}else{ document.write("<link href='../css/3wap.css' rel='stylesheet' type='text/css'>");}</script><script src='../../js/3.js'></script><div class='div2'><div class='heading_nav'><ul><div><li><a href='../../index.html'>首页</a></li>
</div><div onclick='hidden1()' >分享</div>
</ul></div></div>
<div id='heading_nav2'> 
<li class='row' >
<div class='social-share' data-mode='prepend'><a href='javascript:' class='social-share-icon icon-heart'></a></div></li></div><script charset='utf-8' src='../../3/js/hengfu.js'></script><script charset='utf-8' src='../../3/js/hengfu2.js'></script><hr><div class='div1'><div class='biaoti'><center>2019基于python的网络爬虫系列，爬取糗事百科</center></div><div class='banquan'>原文出处:本文由博客园博主chenXSSX提供。<br/>
原文连接:https://www.cnblogs.com/chx123/p/11692125.html</div><br>
    <p>**因为糗事百科的URL改变，正则表达式也发生了改变，导致了网上许多的代码不能使用，所以写下了这一篇博客，希望对大家有所帮助，谢谢！**</p>
<p>废话不多说，直接上代码。</p>
<p>为了方便提取数据，我用的是beautifulsoup库和requests</p>
<p>![使用requests和bs4](https://img-blog.csdnimg.cn/20191017093920758.png)</p>
<p>``## 具体代码如下</p>
<p><br />```<br />import requests<br />from bs4 import BeautifulSoup</p>
<p><br />def download_page(url):<br />    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:6.0) Gecko/20100101 Firefox/6.0"}<br />    r = requests.get(url, headers=headers)<br />    return r.text</p>
<p><br />def get_content(html):<br />    soup = BeautifulSoup(html, 'html.parser')<br />    con = soup.find(id='main')<br />    con_list = con.find_all('div', class_="cat_llb")<br />    for i in con_list:<br />        author = i.find('h3').string  # 获取名字<br />        content = i.find('div', id="endtext").get_text()  # 获取内容<br />        save_txt(author, content)</p>
<p><br />def save_txt(*args):<br />    for i in args:<br />        with open('qiubai.txt', 'a', encoding='utf-8') as f:</p>
<p>            f.write(i+'\n'+'\n')</p>
<p><br /># def save_txt(str):<br />#     for i in str:<br />#<br />#         with open('qiubai.txt', 'a', encoding='utf-8') as f:<br />#             f.write(str + '\n')<br />#             f.write(i)</p>
<p>&nbsp;</p>
<p>def main():<br />    # 可以构造如下 url，</p>
<p>    for i in range(1, 20):</p>
<p>        url = 'http://www.lovehhy.net/Joke/Detail/QSBK/{}'.format(i)<br />        html = download_page(url)<br />        get_content(html)</p>
<p><br />if __name__ == '__main__':<br />    main()</p>
<p>```</p>
<p>哦 ,对了，新网站的地址是http://www.lovehhy.net/Joke/Detail/QSBK/<br />有什么不懂得欢迎留言</p>
</div>
</div><hr><script charset='utf-8' src='../../js/sming.js'></script></body></html>