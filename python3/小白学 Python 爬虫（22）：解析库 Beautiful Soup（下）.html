<html><head><meta charset='utf-8'><meta name='viewport' content='width=device-width, initial-scale=1'>
<meta name='applicable-device' content='pc'><meta name='keywords' content='电脑,电脑讲解,电脑技术,编程,电脑故障维修小白学 Python 爬虫（22）：解析库 Beautiful Soup（下）' />
<script src='../../highlight/highlight.pack.js'></script>
<link rel='stylesheet' type='text/css' href='../../highlight/styles/monokai.css'/>

<link rel='stylesheet' href='../../fenxiang/dist/css/share.min.css'>
<script src='../../fenxiang/src/js/social-share.js'></script>
<script src='../../fenxiang/src/js/qrcode.js'></script>

</head><body><script>hljs.initHighlightingOnLoad();</script><script>
var system ={};  
var p = navigator.platform;       
system.win = p.indexOf('Win') == 0;  
system.mac = p.indexOf('Mac') == 0;  
system.x11 = (p == 'X11') || (p.indexOf('Linux') == 0);     
if(system.win||system.mac||system.xll){
document.write("<link href='../css/3.css' rel='stylesheet' type='text/css'>");}else{ document.write("<link href='../css/3wap.css' rel='stylesheet' type='text/css'>");}</script><script src='../../js/3.js'></script><div class='div2'><div class='heading_nav'><ul><div><li><a href='../../index.html'>首页</a></li>
</div><div onclick='hidden1()' >分享</div>
</ul></div></div>
<div id='heading_nav2'> 
<li class='row' >
<div class='social-share' data-mode='prepend'><a href='javascript:' class='social-share-icon icon-heart'></a></div></li></div><script charset='utf-8' src='../../3/js/hengfu.js'></script><script charset='utf-8' src='../../3/js/hengfu2.js'></script><hr><div class='div1'><div class='biaoti'><center>小白学 Python 爬虫（22）：解析库 Beautiful Soup（下）</center></div><div class='banquan'>原文出处:本文由博客园博主极客挖掘机提供。<br/>
原文连接:https://www.cnblogs.com/babycomeon/p/12065868.html</div><br>
    <p><img src="./images/小白学 Python 爬虫（22）：解析库 Beautiful Soup（下）0.png" /></p>
<blockquote>
<p>人生苦短，我用 Python</p>
</blockquote>
<p>前文传送门：</p>
<p><a href="https://www.geekdigging.com/2019/11/13/3303836941/">小白学 Python 爬虫（1）：开篇</a></p>
<p><a href="https://www.geekdigging.com/2019/11/20/2586166930/">小白学 Python 爬虫（2）：前置准备（一）基本类库的安装</a></p>
<p><a href="https://www.geekdigging.com/2019/11/21/1005563697/">小白学 Python 爬虫（3）：前置准备（二）Linux基础入门</a></p>
<p><a href="https://www.geekdigging.com/2019/11/22/3679472340/">小白学 Python 爬虫（4）：前置准备（三）Docker基础入门</a></p>
<p><a href="https://www.geekdigging.com/2019/11/24/334078215/">小白学 Python 爬虫（5）：前置准备（四）数据库基础</a></p>
<p><a href="https://www.geekdigging.com/2019/11/25/1881661601/">小白学 Python 爬虫（6）：前置准备（五）爬虫框架的安装</a></p>
<p><a href="https://www.geekdigging.com/2019/11/26/1197821400/">小白学 Python 爬虫（7）：HTTP 基础</a></p>
<p><a href="https://www.geekdigging.com/2019/11/27/101847406/">小白学 Python 爬虫（8）：网页基础</a></p>
<p><a href="https://www.geekdigging.com/2019/11/28/1668465912/">小白学 Python 爬虫（9）：爬虫基础</a></p>
<p><a href="https://www.geekdigging.com/2019/12/01/2475257648/">小白学 Python 爬虫（10）：Session 和 Cookies</a></p>
<p><a href="https://www.geekdigging.com/2019/12/02/2333822325/">小白学 Python 爬虫（11）：urllib 基础使用（一）</a></p>
<p><a href="https://www.geekdigging.com/2019/12/03/819896244/">小白学 Python 爬虫（12）：urllib 基础使用（二）</a></p>
<p><a href="https://www.geekdigging.com/2019/12/04/2992515886/">小白学 Python 爬虫（13）：urllib 基础使用（三）</a></p>
<p><a href="https://www.geekdigging.com/2019/12/05/104488944/">小白学 Python 爬虫（14）：urllib 基础使用（四）</a></p>
<p><a href="https://www.geekdigging.com/2019/12/07/2788855167/">小白学 Python 爬虫（15）：urllib 基础使用（五）</a></p>
<p><a href="https://www.geekdigging.com/2019/12/09/1691033431/">小白学 Python 爬虫（16）：urllib 实战之爬取妹子图</a></p>
<p><a href="https://www.geekdigging.com/2019/12/10/1910005577/">小白学 Python 爬虫（17）：Requests 基础使用</a></p>
<p><a href="https://www.geekdigging.com/2019/12/11/1468953802/">小白学 Python 爬虫（18）：Requests 进阶操作</a></p>
<p><a href="https://www.geekdigging.com/2019/12/12/3568648672/">小白学 Python 爬虫（19）：Xpath 基操</a></p>
<p><a href="https://www.geekdigging.com/2019/12/13/2569867940/">小白学 Python 爬虫（20）：Xpath 进阶</a></p>
<p><a href="https://www.geekdigging.com/2019/12/15/2789385418/">小白学 Python 爬虫（21）：解析库 Beautiful Soup（上）</a></p>
<h2 id="引言">引言</h2>
<p>前面一篇我们介绍的选择方法都是通过属性来进行选择的，这种方法使用起来非常简单，但是，如果 DOM 结构比较复杂的话，这种方法就不是那么友好了。</p>
<p>所以 Beautiful Soup 还为我们提供了一些搜索方法，如 <code>find_all()</code> 和 <code>find()</code> ， DOM 节点不好直接用属性方法来表示，我们可以直接搜索嘛~~~</p>
<h2 id="find_all">find_all()</h2>
<p>先看下语法结构：</p>
<pre><code><code>find_all( name , attrs , recursive , string , **kwargs )</code></pre>
<p><code>find_all()</code> 方法搜索当前 tag 的所有 tag 子节点，并判断是否符合过滤器的条件。</p>
<h3 id="name">name</h3>
<p>name 参数可以查找所有名字为 name 的 tag ，字符串对象会被自动忽略掉。</p>
<pre><code><code>from bs4 import BeautifulSoup

html_doc = &quot;&quot;&quot;
&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse&#39;s story&lt;/title&gt;&lt;/head&gt;
&lt;body&gt;
&lt;p class=&quot;title&quot;&gt;&lt;b&gt;The Dormouse&#39;s story&lt;/b&gt;&lt;/p&gt;

&lt;p class=&quot;story&quot;&gt;Once upon a time there were three little sisters; and their names were
&lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,
&lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and
&lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;;
and they lived at the bottom of a well.&lt;/p&gt;

&lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;
&quot;&quot;&quot;

soup = BeautifulSoup(html_doc, &#39;lxml&#39;)

print(soup.find_all(name = &quot;a&quot;))
print(type(soup.find_all(name = &quot;a&quot;)[0]))</code></pre>
<p>结果如下：</p>
<pre><code><code>[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;]
&lt;class &#39;bs4.element.Tag&#39;&gt;</code></pre>
<p>这次的示例换成了字符串，主要是为了各位同学看起来方便，再也不用去对照着图片看了。</p>
<p>这个示例我们使用了 <code>find_all()</code> 方法，并且传入了 <code>name</code> 参数，值为 <code>a</code> ，含义是我们要查找所有的 <code>&lt;a&gt;</code> 节点，可以看到，返回的结果数据类型是列表，长度为 3 ，并且元素类型为 <code>bs4.element.Tag</code> 。</p>
<p>因为元素类型为 <code>bs4.element.Tag</code> ，我们可以通过前一篇文章介绍的属性直接获取其中的内容：</p>
<pre><code><code>for a in soup.find_all(name = &quot;a&quot;):
    print(a.string)</code></pre>
<p>结果如下：</p>
<pre><code><code>Elsie
Lacie
Tillie</code></pre>
<h3 id="attrs">attrs</h3>
<p>除了可以通过 name 进行搜索，我们还可以通过属性进行查询：</p>
<pre><code><code>print(soup.find_all(attrs={&#39;id&#39;: &#39;link1&#39;}))
print(soup.find_all(attrs={&#39;id&#39;: &#39;link2&#39;}))
print(type(soup.find_all(attrs={&#39;id&#39;: &#39;link1&#39;})))
print(type(soup.find_all(attrs={&#39;id&#39;: &#39;link2&#39;})))</code></pre>
<p>结果如下：</p>
<pre><code><code>[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;]
[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;]
&lt;class &#39;bs4.element.ResultSet&#39;&gt;
&lt;class &#39;bs4.element.ResultSet&#39;&gt;</code></pre>
<p>这个示例我们传入的是 <code>attrs</code> 参数，参数的数据类型是字典。</p>
<h3 id="string">string</h3>
<p>这个参数可用来匹配节点的文本，传入的形式可以是字符串，可以是正则表达式对象：</p>
<pre><code><code>import re

print(soup.find_all(text=re.compile(&#39;sisters&#39;)))</code></pre>
<p>结果如下：</p>
<pre><code><code>[&#39;Once upon a time there were three little sisters; and their names were\n&#39;]</code></pre>
<h3 id="keyword">keyword</h3>
<p>如果一个指定名字的参数不是搜索内置的参数名，搜索时会把该参数当作指定名字 tag 的属性来搜索，比如下面的示例我们直接搜索 <code>id</code> 为 <code>link</code> 的节点和 <code>class</code> 为 <code>title</code> 的节点：</p>
<pre><code><code>print(soup.find_all(id=&#39;link1&#39;))
print(soup.find_all(class_=&#39;title&#39;))</code></pre>
<p>结果如下：</p>
<pre><code><code>[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;]
[&lt;p class=&quot;title&quot;&gt;&lt;b&gt;The Dormouse&#39;s story&lt;/b&gt;&lt;/p&gt;]</code></pre>
<p>当然，我们也可以使用多个指定名字的参数同时过滤 tag 的多个属性：</p>
<pre><code><code>print(soup.find_all(href=re.compile(&quot;elsie&quot;), id=&#39;link1&#39;))</code></pre>
<p>结果如下：</p>
<pre><code><code>[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;]</code></pre>
<p>有些 tag 属性在搜索不能使用，比如 HTML5 中的 data-* 属性，这时就需要用到上面介绍过的 attrs 参数了。</p>
<h2 id="find">find()</h2>
<p><code>find()</code> 和 <code>find_all()</code> 非常的像，只不过 <code>find()</code> 不再像 <code>find_all()</code> 一样直接返回所有的匹配节点，而是只返回第一个匹配的元素。举几个简单的栗子：</p>
<pre><code><code>print(soup.find(name = &quot;a&quot;))
print(type(soup.find(name = &quot;a&quot;)))</code></pre>
<p>结果如下：</p>
<pre><code><code>&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;
&lt;class &#39;bs4.element.Tag&#39;&gt;</code></pre>
<p>其余的查询方法各位同学可以参考官方文档，小编这里简单列举一下：</p>
<ul>
<li><code>find_parents()</code> 和 <code>find_parent()</code> ： 用来搜索当前节点的父辈节点。</li>
<li><code>find_next_siblings()</code> 和 <code>find_next_sibling()</code> ： 前者返回后面所有的兄弟节点，后者返回后面第一个兄弟节点。</li>
<li><code>find_previous_siblings()</code> 和 <code>find_previous_sibling()</code> ： 前者返回前面所有的兄弟节点，后者返回前面第一个兄弟节点。</li>
<li><code>find_all_next()</code> 和 <code>find_next()</code> ：前者返回节点后所有符合条件的节点，后者返回第一个符合条件的节点。</li>
<li><code>find_all_previous()</code> 和 <code>find_previous()</code> ：前者返回节点后所有符合条件的节点，后者返回第一个符合条件的节点。</li>
</ul>
<h2 id="css">CSS</h2>
<p>Beautiful Soup 除了提供前面这些属性选择、搜索方法等方式来获取节点，还提供了另外一种选择器 —— CSS 选择器。</p>
<p>如果对 CSS 选择器不熟的话，可以参考：<a href="https://www.w3school.com.cn/css/index.asp" class="uri">https://www.w3school.com.cn/css/index.asp</a> 。</p>
<p>使用 CSS 选择器方法非常简单，只需要调用 select() 方法，传入相应的 CSS 选择器即可，还是写几个简单的示例：</p>
<pre><code><code>print(soup.select(&#39;#link1&#39;))
print(type(soup.select(&#39;#link1&#39;)[0]))
print(soup.select(&#39;.story .sister&#39;))</code></pre>
<p>结果如下：</p>
<pre><code><code>&lt;class &#39;bs4.element.Tag&#39;&gt;
[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;]</code></pre>
<p>可以看到，我们使用 CSS 选择器获得的结果同样会是一个列表，并且里面的元素同样是 <code>bs4.element.Tag</code> ，这就意味着我们可以使用它的属性来获取对应的信息。</p>
<h2 id="小结">小结</h2>
<p>Beautiful Soup 就这么简单的介绍完了，稍微做点小总结：</p>
<ul>
<li>在选择解析器的时候尽量选择 <code>lxml</code> ，官方推荐，据说是快。</li>
<li>节点属性筛选虽然简单但是功能有点弱鸡。</li>
<li>find_all() 和 find() 其实可以很方便的帮助我们完成绝大多数的工作。</li>
<li>CSS 选择器推荐有经验的同学使用，毕竟嘛，选择 DOM 节点，还是 CSS 选择器来的方便好使不是么？</li>
</ul>
<h2 id="示例代码">示例代码</h2>
<p>本系列的所有代码小编都会放在代码管理仓库 Github 和 Gitee 上，方便大家取用。</p>
<p><a href="https://github.com/meteor1993/python-learning/tree/master/python-spider/bs4-demo" title="示例代码-Github">示例代码-Github</a></p>
<p><a href="https://gitee.com/inwsy/python-learning/tree/master/python-spider/bs4-demo" title="示例代码-Gitee">示例代码-Gitee</a></p>
<h2 id="参考">参考</h2>
<p><a href="https://beautifulsoup.readthedocs.io/zh_CN/v4.4.0/#" class="uri">https://beautifulsoup.readthedocs.io/zh_CN/v4.4.0/#</a></p>

</div>
</div><hr><script charset='utf-8' src='../../js/sming.js'></script></body></html>