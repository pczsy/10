<html><head><meta charset='utf-8'><meta name='viewport' content='width=device-width, initial-scale=1'>
<meta name='applicable-device' content='pc'><meta name='keywords' content='电脑,电脑讲解,电脑技术,编程,电脑故障维修使用scrapy框架爬取全书网书籍信息。' />
<script src='../../highlight/highlight.pack.js'></script>
<link rel='stylesheet' type='text/css' href='../../highlight/styles/monokai.css'/>

<link rel='stylesheet' href='../../fenxiang/dist/css/share.min.css'>
<script src='../../fenxiang/src/js/social-share.js'></script>
<script src='../../fenxiang/src/js/qrcode.js'></script>

</head><body><script>hljs.initHighlightingOnLoad();</script><script>
var system ={};  
var p = navigator.platform;       
system.win = p.indexOf('Win') == 0;  
system.mac = p.indexOf('Mac') == 0;  
system.x11 = (p == 'X11') || (p.indexOf('Linux') == 0);     
if(system.win||system.mac||system.xll){
document.write("<link href='../css/3.css' rel='stylesheet' type='text/css'>");}else{ document.write("<link href='../css/3wap.css' rel='stylesheet' type='text/css'>");}</script><script src='../../js/3.js'></script><div class='div2'><div class='heading_nav'><ul><div><li><a href='../../index.html'>首页</a></li>
</div><div onclick='hidden1()' >分享</div>
</ul></div></div>
<div id='heading_nav2'> 
<li class='row' >
<div class='social-share' data-mode='prepend'><a href='javascript:' class='social-share-icon icon-heart'></a></div></li></div><script charset='utf-8' src='../../3/js/hengfu.js'></script><script charset='utf-8' src='../../3/js/hengfu2.js'></script><hr><div class='div1'><div class='biaoti'><center>使用scrapy框架爬取全书网书籍信息。</center></div><div class='banquan'>原文出处:本文由博客园博主记住我忘记我提供。<br/>
原文连接:https://www.cnblogs.com/nmsghgnv/p/11341424.html</div><br>
    <p>爬取的内容：书籍名称，作者名称，书籍简介，全书网5041页,写入mysql数据库和.txt文件</p>
<p>1，创建scrapy项目</p>
<div class="cnblogs_code">
<pre><code>scrapy startproject numberone</pre>
</div>
<p>2，创建爬虫主程序</p>
<div class="cnblogs_code">
<pre><code><span style="color: #000000;">cd numberone

scrapy genspider quanshuwang www.quanshuwang.com</span></pre>
</div>
<p>3，setting中设置请求头</p>
<div class="cnblogs_code">
<pre><code>USER_AGENT = <span style="color: #800000;">"</span><span style="color: #800000;">Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.71 Safari/537.36</span><span style="color: #800000;">"</span></pre>
</div>
<p>4，item中设置要爬取的字段</p>
<div class="cnblogs_code">
<pre><code><span style="color: #0000ff;">class</span><span style="color: #000000;"> NumberoneItem(scrapy.Item):
    </span><span style="color: #008000;">#</span><span style="color: #008000;"> define the fields for your item here like:</span>
    <span style="color: #008000;">#</span><span style="color: #008000;"> name = scrapy.Field()</span>
    book_author =<span style="color: #000000;"> scrapy.Field()
    book_name </span>=<span style="color: #000000;"> scrapy.Field()
    book_desc </span>= scrapy.Field()</pre>
</div>
<p>5，quanshuwang.py主程序中写获取数据的主代码</p>
<div class="cnblogs_code">
<pre><code><span style="color: #008000;">#</span><span style="color: #008000;"> -*- coding: utf-8 -*-</span>
<span style="color: #0000ff;">import</span><span style="color: #000000;"> scrapy
</span><span style="color: #0000ff;">from</span> numberone.items <span style="color: #0000ff;">import</span><span style="color: #000000;"> NumberoneItem

</span><span style="color: #0000ff;">class</span><span style="color: #000000;"> QiubaiSpider(scrapy.Spider):
    name </span>= <span style="color: #800000;">'</span><span style="color: #800000;">quanshuwang</span><span style="color: #800000;">'</span>
    <span style="color: #008000;">#</span><span style="color: #008000;"> 这句话是定义爬虫爬取的范围，最好注释掉</span>
    <span style="color: #008000;">#</span><span style="color: #008000;"> allowed_domains = ['www.qiushibaike.com']</span>
    <span style="color: #008000;">#</span><span style="color: #008000;"> 开始爬取的路由</span>
    start_urls = [<span style="color: #800000;">'</span><span style="color: #800000;">http://www.quanshuwang.com/list/0_1.html</span><span style="color: #800000;">'</span><span style="color: #000000;">]
    </span><span style="color: #0000ff;">def</span><span style="color: #000000;"> parse(self, response):
        book_list </span>= response.xpath(<span style="color: #800000;">'</span><span style="color: #800000;">//ul[@class="seeWell cf"]/li</span><span style="color: #800000;">'</span><span style="color: #000000;">)
        </span><span style="color: #0000ff;">for</span> i <span style="color: #0000ff;">in</span><span style="color: #000000;"> book_list:
            item </span>=<span style="color: #000000;"> NumberoneItem()
            item[</span><span style="color: #800000;">'</span><span style="color: #800000;">book_name</span><span style="color: #800000;">'</span>] = i.xpath(<span style="color: #800000;">'</span><span style="color: #800000;">./span/a/text()</span><span style="color: #800000;">'</span><span style="color: #000000;">).extract_first()
            item[</span><span style="color: #800000;">'</span><span style="color: #800000;">book_author</span><span style="color: #800000;">'</span>] = i.xpath(<span style="color: #800000;">'</span><span style="color: #800000;">./span/a[2]/text()</span><span style="color: #800000;">'</span><span style="color: #000000;">).extract_first()
            item[</span><span style="color: #800000;">'</span><span style="color: #800000;">book_desc</span><span style="color: #800000;">'</span>] = i.xpath(<span style="color: #800000;">'</span><span style="color: #800000;">./span/em/text()</span><span style="color: #800000;">'</span><span style="color: #000000;">).extract_first()
            </span><span style="color: #0000ff;">yield</span><span style="color: #000000;"> item
        next </span>= response.xpath(<span style="color: #800000;">'</span><span style="color: #800000;">//a[@class="next"]/@href</span><span style="color: #800000;">'</span><span style="color: #000000;">).extract_first()
        </span><span style="color: #0000ff;">if</span><span style="color: #000000;"> next:
            </span><span style="color: #0000ff;">yield</span> scrapy.Request(next, callback=self.parse)</pre>
</div>
<p>6，pipelines.py管道文件中文件中写持久化保存.txt和mysql。</p>
<div class="cnblogs_code">
<pre><code><span style="color: #008000;">#</span><span style="color: #008000;"> -*- coding: utf-8 -*-</span>

<span style="color: #008000;">#</span><span style="color: #008000;"> Define your item pipelines here</span><span style="color: #008000;">
#
#</span><span style="color: #008000;"> Don't forget to add your pipeline to the ITEM_PIPELINES setting</span><span style="color: #008000;">
#</span><span style="color: #008000;"> See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span>
<span style="color: #0000ff;">import</span><span style="color: #000000;"> pymysql
</span><span style="color: #008000;">#</span><span style="color: #008000;"> 写入文件的类</span>
<span style="color: #0000ff;">class</span><span style="color: #000000;"> NumberonePipeline(object):
    f </span>=<span style="color: #000000;"> None
    </span><span style="color: #0000ff;">def</span><span style="color: #000000;"> open_spider(self,spider):
        self.f </span>= open(<span style="color: #800000;">'</span><span style="color: #800000;">全书网.txt</span><span style="color: #800000;">'</span>,<span style="color: #800000;">'</span><span style="color: #800000;">a+</span><span style="color: #800000;">'</span>,encoding=<span style="color: #800000;">'</span><span style="color: #800000;">utf-8</span><span style="color: #800000;">'</span><span style="color: #000000;">)
    </span><span style="color: #0000ff;">def</span><span style="color: #000000;"> process_item(self, item, spider):
        </span><span style="color: #0000ff;">print</span>(item[<span style="color: #800000;">'</span><span style="color: #800000;">book_name</span><span style="color: #800000;">'</span>]+<span style="color: #800000;">'</span><span style="color: #800000;">：正在写入文件...</span><span style="color: #800000;">'</span><span style="color: #000000;">)
        book_name </span>= item[<span style="color: #800000;">'</span><span style="color: #800000;">book_name</span><span style="color: #800000;">'</span><span style="color: #000000;">]
        book_author </span>= item[<span style="color: #800000;">'</span><span style="color: #800000;">book_author</span><span style="color: #800000;">'</span><span style="color: #000000;">]
        book_desc </span>= item[<span style="color: #800000;">'</span><span style="color: #800000;">book_desc</span><span style="color: #800000;">'</span><span style="color: #000000;">]
        self.f.write(</span><span style="color: #800000;">'</span><span style="color: #800000;">书名：</span><span style="color: #800000;">'</span>+book_name+<span style="color: #800000;">'</span><span style="color: #800000;">\n</span><span style="color: #800000;">'</span>+<span style="color: #800000;">'</span><span style="color: #800000;">作者：</span><span style="color: #800000;">'</span>+book_author+<span style="color: #800000;">'</span><span style="color: #800000;">\n</span><span style="color: #800000;">'</span>+<span style="color: #800000;">'</span><span style="color: #800000;">书籍简介：</span><span style="color: #800000;">'</span>+book_desc+<span style="color: #800000;">'</span><span style="color: #800000;">\n\n</span><span style="color: #800000;">'</span><span style="color: #000000;">)
        </span><span style="color: #0000ff;">return</span><span style="color: #000000;"> item
    </span><span style="color: #0000ff;">def</span><span style="color: #000000;"> close_spider(self,spider):
        self.f.close()
</span><span style="color: #008000;">#</span><span style="color: #008000;"> 写入数据库的类</span>
<span style="color: #0000ff;">class</span><span style="color: #000000;"> MysqlPipeline(object):
    conn </span>=<span style="color: #000000;"> None
    mycursor </span>=<span style="color: #000000;"> None
    </span><span style="color: #0000ff;">def</span><span style="color: #000000;"> open_spider(self,spider):
        self.conn </span>= pymysql.connect(host=<span style="color: #800000;">'</span><span style="color: #800000;">172.16.25.4</span><span style="color: #800000;">'</span>,user=<span style="color: #800000;">'</span><span style="color: #800000;">root</span><span style="color: #800000;">'</span>,password=<span style="color: #800000;">'</span><span style="color: #800000;">root</span><span style="color: #800000;">'</span>,db=<span style="color: #800000;">'</span><span style="color: #800000;">quanshuwang</span><span style="color: #800000;">'</span><span style="color: #000000;">)
        self.mycursor </span>=<span style="color: #000000;"> self.conn.cursor()
    </span><span style="color: #0000ff;">def</span><span style="color: #000000;"> process_item(self, item, spider):
        </span><span style="color: #0000ff;">print</span>(item[<span style="color: #800000;">'</span><span style="color: #800000;">book_name</span><span style="color: #800000;">'</span>] + <span style="color: #800000;">'</span><span style="color: #800000;">：正在写数据库...</span><span style="color: #800000;">'</span><span style="color: #000000;">)
        book_name </span>= item[<span style="color: #800000;">'</span><span style="color: #800000;">book_name</span><span style="color: #800000;">'</span><span style="color: #000000;">]
        book_author </span>= item[<span style="color: #800000;">'</span><span style="color: #800000;">book_author</span><span style="color: #800000;">'</span><span style="color: #000000;">]
        book_desc </span>= item[<span style="color: #800000;">'</span><span style="color: #800000;">book_desc</span><span style="color: #800000;">'</span><span style="color: #000000;">]
        self.mycursor </span>=<span style="color: #000000;"> self.conn.cursor()
        sql </span>= <span style="color: #800000;">'</span><span style="color: #800000;">insert into qsw VALUES (null,"%s","%s","%s")</span><span style="color: #800000;">'</span>%<span style="color: #000000;">(book_name,book_author,book_desc)
        bool </span>=<span style="color: #000000;"> self.mycursor.execute(sql)
        self.conn.commit()
        </span><span style="color: #0000ff;">return</span><span style="color: #000000;"> item
    </span><span style="color: #0000ff;">def</span><span style="color: #000000;"> close_spider(self,spider):
        self.conn.close()
        self.mycursor.close()</span></pre>
</div>
<p>7，setting.py文件中打开管道文件。</p>
<div class="cnblogs_code">
<pre><code>ITEM_PIPELINES =<span style="color: #000000;"> {
   </span><span style="color: #800000;">'</span><span style="color: #800000;">numberone.pipelines.NumberonePipeline</span><span style="color: #800000;">'</span>: 300<span style="color: #000000;">,
   </span><span style="color: #800000;">'</span><span style="color: #800000;">numberone.pipelines.MysqlPipeline</span><span style="color: #800000;">'</span>: 400<span style="color: #000000;">,

}</span></pre>
</div>
<p>8，执行运行爬虫的命令</p>
<div class="cnblogs_code">
<pre><code>scrapy crawl quanshuwang --nolog</pre>
</div>
<p>9,控制台输出</p>
<div class="cnblogs_code">
<pre><code><span style="color: #000000;">贵府嫡女：正在写数据库...
随身空间农女翻身记：正在写入文件...
随身空间农女翻身记：正在写数据库...
阴间商人：正在写入文件...
阴间商人：正在写数据库...
我的美味有属性：正在写入文件...
我的美味有属性：正在写数据库...
剑仙修炼纪要：正在写入文件...
剑仙修炼纪要：正在写数据库...
在阴间上班的日子：正在写入文件...
在阴间上班的日子：正在写数据库...
轮回之鸿蒙传说：正在写入文件...
轮回之鸿蒙传说：正在写数据库...
末日星城：正在写入文件...
末日星城：正在写数据库...
异域神州道：正在写入文件...
异域神州道：正在写数据库...</span></pre>
</div>
<p>10，打开文件和数据库查看是否写入成功</p>
<p><img src="./images/使用scrapy框架爬取全书网书籍信息。0.png" alt="" /></p>
<p><img src="./images/使用scrapy框架爬取全书网书籍信息。1.png" alt="" /></p>
<p>done。</p>
<p>&nbsp;</p>
</div>
</div><hr><script charset='utf-8' src='../../js/sming.js'></script></body></html>