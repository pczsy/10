<html><head><meta charset='utf-8'><meta name='viewport' content='width=device-width, initial-scale=1'>
<meta name='applicable-device' content='pc'><meta name='keywords' content='电脑,电脑讲解,电脑技术,编程,电脑故障维修Urllib库的使用' />
<script src='../../highlight/highlight.pack.js'></script>
<link rel='stylesheet' type='text/css' href='../../highlight/styles/monokai.css'/>

<link rel='stylesheet' href='../../fenxiang/dist/css/share.min.css'>
<script src='../../fenxiang/src/js/social-share.js'></script>
<script src='../../fenxiang/src/js/qrcode.js'></script>

</head><body><script>hljs.initHighlightingOnLoad();</script><script>
var system ={};  
var p = navigator.platform;       
system.win = p.indexOf('Win') == 0;  
system.mac = p.indexOf('Mac') == 0;  
system.x11 = (p == 'X11') || (p.indexOf('Linux') == 0);     
if(system.win||system.mac||system.xll){
document.write("<link href='../css/3.css' rel='stylesheet' type='text/css'>");}else{ document.write("<link href='../css/3wap.css' rel='stylesheet' type='text/css'>");}</script><script src='../../js/3.js'></script><div class='div2'><div class='heading_nav'><ul><div><li><a href='../../index.html'>首页</a></li>
</div><div onclick='hidden1()' >分享</div>
</ul></div></div>
<div id='heading_nav2'> 
<li class='row' >
<div class='social-share' data-mode='prepend'><a href='javascript:' class='social-share-icon icon-heart'></a></div></li></div><script charset='utf-8' src='../../3/js/hengfu.js'></script><script charset='utf-8' src='../../3/js/hengfu2.js'></script><hr><div class='div1'><div class='biaoti'><center>Urllib库的使用</center></div><div class='banquan'>原文出处:本文由博客园博主纪宇-年华提供。<br/>
原文连接:https://www.cnblogs.com/jiyu-hlzy/p/11780041.html</div><br>
    <ol>
<li>urllib库</li>
<li>urllib3库</li>
<li>爬虫一般流程</li>
</ol>
<p><span style="font-size: 18px;">urllib</span></p>
<p><span style="font-size: 18px;"><span style="font-size: 16px;">urllib 是一个用来处理网络请求的python标准库，它包含4个模块</span></span></p>
<p>&nbsp;</p>
<p><span style="font-size: 18px;"><span style="font-size: 16px;">urllib.request&nbsp; &nbsp; &nbsp; 　　　　　　请求模块，用于发起网络请求</span></span></p>
<p>request模块主要负责构造和发起网络请求，并在其中添加Headers，Proxy等，利用它可以模拟浏览器的请求发起过程</p>
<p>发起网络请求 、添加Headers 、操作cookie 、使用代理</p>
<p>&nbsp;</p>
<p>1、urlopen方法　　　　　　　　　　一个简单发送网络请求的方法</p>
<p>url：字符串格式的url</p>
<p>data：默认会发送GET请求，当传入data参数时，则会发起POST请求，data参数是字节类型、者类文件对象或可迭代对象</p>
<p>timeout：设置超时（以秒为单位），如果请求超过设置时间，则抛出异常。timeout没有指定则用系统默认设置，timeout只对，http，https以及ftp连接起作用</p>
<p><img src="./images/Urllib库的使用0.png" alt="" /></p>
<p><img src="./images/Urllib库的使用1.png" alt="" /></p>
<p>&nbsp;</p>
<p>2、Request对象</p>
<p>利用urlopen可以发起最基本的请求，但这几个简单的参数不足以构建一个完整的请求，可以利用更强大的Request对象来构建更加完整的请求</p>
<p>2.1、请求头添加　　　　　　　　两种方式，一种可以添加多个，为字典类型，一种可以添加一个，为元组类型</p>
<p>通过urllib发送的请求会有一个默认的Headers:&ldquo;User-Agent&rdquo;:&ldquo;Python-urllib/3.*&rdquo;，指明请求是由urllib发送的</p>
<p>所以遇到一些验证User-Agent的网站时，需要我们自定义Headers把自己伪装起来</p>
<p><img src="./images/Urllib库的使用2.png" alt="" /></p>
<p><img src="./images/Urllib库的使用3.png" alt="" /></p>
<p>2.2操作cookie　　　　　　　　在爬虫中，对cookie的处理非常重要&nbsp;</p>
<p>cookiejar　　　　　　　　　　 查看cookie信息</p>
<p><img src="./images/Urllib库的使用4.png" alt="" /></p>
<p>2.3设置代理</p>
<p><img src="./images/Urllib库的使用5.png" alt="" /></p>
<p><img src="./images/Urllib库的使用6.png" alt="" /></p>
<p>&nbsp;</p>
<p>3、Response对象</p>
<p>read() 　　&nbsp; &nbsp;获取响应返回的数据，只能用一次&nbsp;　　　　　　　　　　　　readline()&nbsp; 读取一行&nbsp;</p>
<p>info() 　&nbsp; &nbsp;　 获取响应头信息&nbsp;</p>
<p>geturl() 　 　获取访问的url</p>
<p>getcode()&nbsp; &nbsp; &nbsp;返回状态码&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p><span style="font-size: 18px;"><span style="font-size: 16px;">urllib.parse&nbsp; &nbsp; &nbsp; &nbsp; 　　　　　　&nbsp;解析模块，用于解析URL</span></span></p>
<p>url中只能包含ascii字符，在实际操作过程中，get请求通过url传递的参数中会有大量的特殊字符，例如汉字，那么就需要进行url编码</p>
<p>字符串参数：parse.quote() 编码　　　parse.unquote() 解码</p>
<p><img src="./images/Urllib库的使用7.png" alt="" /></p>
<p><img src="./images/Urllib库的使用8.png" alt="" /></p>
<p>在发送请求的时候，往往会需要传递很多的参数，如果用字符串方法去拼接会比较麻烦，parse.urlencode()方法用来拼接字典类型的url参数</p>
<p>字典参数：parse.urlencode() 编码 　　parse.parse_qs() 解码</p>
<p><img src="./images/Urllib库的使用9.png" alt="" /></p>
<p><img src="./images/Urllib库的使用10.png" alt="" /></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p><span style="font-size: 18px;"><span style="font-size: 16px;">urllib.error&nbsp; &nbsp; &nbsp; &nbsp;　　　　&nbsp; 　　 异常处理模块，用于处理request引起的异常</span></span></p>
<p>主要包含URLError和HTTPError</p>
<p>URLError：是error异常模块的基类，由request模块产生的异常都可以用这个类来处理</p>
<p>HTTPError：是URLError的子类，主要包含三个属性：　　Code:请求的状态码　　　　reason：错误的原因　　　　headers：响应的报头</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p><span style="font-size: 18px;"><span style="font-size: 16px;">urllib.robotparse&nbsp; &nbsp;　　　&nbsp; &nbsp; &nbsp;　用于解析robots.txt文件</span></span></p>
<p>主要负责处理爬虫协议文件，robots.txt.的解析</p>
<p>robots.txt是一个协议，而不是一个命令</p>
<p>robots.txt是搜索引擎中访问网站的时候要查看的第一个文件</p>
<p>robots.txt文件告诉蜘蛛程序在服务器上什么文件是可以被查看的</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p><span style="font-size: 18px;">urllib3</span></p>
<p><span style="font-size: 16px;">发起请求：urllib3.PoolManager().request()</span></p>
<p>响应对象提供status, data,和header等属性</p>
<p><span style="font-size: 18px;"><span style="font-size: 16px;"><img src="./images/Urllib库的使用11.png" alt="" /></span></span></p>
<p>&nbsp;</p>
<p><span style="font-size: 16px;">JSON content</span></p>
<p>返回的json格式数据可以通过json模块，loads()为字典数据类型</p>
<p>可以通过提供字典类型的参数fields来添加查询参数</p>
<p><img src="./images/Urllib库的使用12.png" alt="" /></p>
<p>&nbsp;load为字典后，可以查看通过url编码过后传输的参数</p>
<p><span style="font-size: 18px;"><span style="font-size: 16px;"><img src="./images/Urllib库的使用13.png" alt="" /></span></span></p>
<p><img src="./images/Urllib库的使用14.png" alt="" /></p>
<p>&nbsp;</p>
<p><span style="font-size: 16px;">Binary content</span></p>
<p>响应返回的数据都是字节类型，对于大量的数据通过stream来处理更好</p>
<p><img src="./images/Urllib库的使用15.png" alt="" /></p>
<p><img src="./images/Urllib库的使用16.png" alt="" /></p>
<p>&nbsp;</p>
<p><span style="font-size: 16px;">ProxyManager</span></p>
<p>进行http代理操作</p>
<p><img src="./images/Urllib库的使用17.png" alt="" /></p>
<p><img src="./images/Urllib库的使用18.png" alt="" /></p>
<p>&nbsp;</p>
<p><span style="font-size: 16px;">添加请求头Headers</span></p>
<p><img src="./images/Urllib库的使用19.png" alt="" /></p>
<p><img src="./images/Urllib库的使用20.png" alt="" /></p>
<p>&nbsp;</p>
<p><span style="font-size: 16px;">提供字典类型的参数field来传递form表单数据</span></p>
<p><span style="font-size: 16px;">对于二进制的数据上传，我们用指定body的方式，设置Content-Type的请求头</span></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p><span style="font-size: 18px;">爬虫开发流程</span></p>
<p><span style="font-size: 18px;"><span style="font-size: 16px;">找到目标数据　　</span></span><span style="font-size: 18px;"><span style="font-size: 16px;">分析请求流程　　</span></span><span style="font-size: 18px;"><span style="font-size: 16px;">构造http请求　　</span></span><span style="font-size: 18px;"><span style="font-size: 16px;">提取清洗数据　　</span></span><span style="font-size: 18px;"><span style="font-size: 16px;">数据持久化</span></span></p>
</div>
</div><hr><script charset='utf-8' src='../../js/sming.js'></script></body></html>