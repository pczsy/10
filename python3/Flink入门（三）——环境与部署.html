<html><head><meta charset='utf-8'><meta name='viewport' content='width=device-width, initial-scale=1'>
<meta name='applicable-device' content='pc'><meta name='keywords' content='电脑,电脑讲解,电脑技术,编程,电脑故障维修Flink入门（三）——环境与部署' />
<script src='../../highlight/highlight.pack.js'></script>
<link rel='stylesheet' type='text/css' href='../../highlight/styles/monokai.css'/>

<link rel='stylesheet' href='../../fenxiang/dist/css/share.min.css'>
<script src='../../fenxiang/src/js/social-share.js'></script>
<script src='../../fenxiang/src/js/qrcode.js'></script>

</head><body><script>hljs.initHighlightingOnLoad();</script><script>
var system ={};  
var p = navigator.platform;       
system.win = p.indexOf('Win') == 0;  
system.mac = p.indexOf('Mac') == 0;  
system.x11 = (p == 'X11') || (p.indexOf('Linux') == 0);     
if(system.win||system.mac||system.xll){
document.write("<link href='../css/3.css' rel='stylesheet' type='text/css'>");}else{ document.write("<link href='../css/3wap.css' rel='stylesheet' type='text/css'>");}</script><script src='../../js/3.js'></script><div class='div2'><div class='heading_nav'><ul><div><li><a href='../../index.html'>首页</a></li>
</div><div onclick='hidden1()' >分享</div>
</ul></div></div>
<div id='heading_nav2'> 
<li class='row' >
<div class='social-share' data-mode='prepend'><a href='javascript:' class='social-share-icon icon-heart'></a></div></li></div><script charset='utf-8' src='../../3/js/hengfu.js'></script><script charset='utf-8' src='../../3/js/hengfu2.js'></script><hr><div class='div1'><div class='biaoti'><center>Flink入门（三）——环境与部署</center></div><div class='banquan'>原文出处:本文由博客园博主独孤风提供。<br/>
原文连接:https://www.cnblogs.com/tree1123/p/12020580.html</div><br>
    <p><img src="./images/Flink入门（三）——环境与部署0.png" alt="file" /></p>
<p>flink是一款开源的大数据流式处理框架，他可以同时批处理和流处理，具有容错性、高吞吐、低延迟等优势，本文简述flink在windows和linux中安装步骤，和示例程序的运行，包括本地调试环境，集群环境。另外介绍Flink的开发工程的构建。</p>
<p>首先要想运行Flink，我们需要下载并解压Flink的二进制包，下载地址如下：<a href="https://flink.apache.org/downloads.html" class="uri">https://flink.apache.org/downloads.html</a></p>
<p>我们可以选择Flink与Scala结合版本，这里我们选择最新的1.9版本<a href="https://www.apache.org/dyn/closer.lua/flink/flink-1.9.0/flink-1.9.0-bin-scala_2.12.tgz">Apache Flink 1.9.0 for Scala 2.12</a>进行下载。</p>
<p>下载成功后，在windows系统中可以通过Windows的bat文件或者Cygwin来运行Flink。</p>
<p>在linux系统中分为单机，集群和Hadoop等多种情况。</p>
<h2 id="通过windows的bat文件运行">通过Windows的bat文件运行</h2>
<p>首先启动cmd命令行窗口，进入flink文件夹，运行bin目录下的<code>start-cluster.bat</code></p>
<p>注意：运行flink需要java环境，请确保系统已经配置java环境变量。</p>
<pre><code><code>$ cd flink
$ cd bin
$ start-cluster.bat
Starting a local cluster with one JobManager process and one TaskManager process.
You can terminate the processes via CTRL-C in the spawned shell windows.
Web interface by default on http://localhost:8081/.</code></pre>
<p><img src="./images/Flink入门（三）——环境与部署1.png" alt="file" /></p>
<p>显示启动成功后，我们在浏览器访问 <a href="http://localhost:8081/可以看到flink的管理页面" class="uri">http://localhost:8081/可以看到flink的管理页面</a>。</p>
<h2 id="通过cygwin运行">通过Cygwin运行</h2>
<p><em>Cygwin</em>是一个在windows平台上运行的类UNIX模拟环境，官网下载：<a href="http://cygwin.com/install.html" class="uri">http://cygwin.com/install.html</a></p>
<p>安装成功后，启动Cygwin终端，运行<code>start-cluster.sh</code>脚本。</p>
<pre><code><code>$ cd flink
$ bin/start-cluster.sh
Starting cluster.</code></pre>
<p>显示启动成功后，我们在浏览器访问 <a href="http://localhost:8081/可以看到flink的管理页面" class="uri">http://localhost:8081/可以看到flink的管理页面</a>。</p>
<p><img src="./images/Flink入门（三）——环境与部署2.png" alt="file" /></p>
<h2 id="linux系统上安装flink">Linux系统上安装flink</h2>
<h4 id="单节点安装">单节点安装</h4>
<p>在Linux上单节点安装方式与cygwin一样，下载<a href="https://www.apache.org/dyn/closer.lua/flink/flink-1.9.0/flink-1.9.0-bin-scala_2.12.tgz">Apache Flink 1.9.0 for Scala 2.12</a>，然后解压后只需要启动start-cluster.sh。</p>
<h4 id="集群安装">集群安装</h4>
<p>集群安装分为以下几步：</p>
<p>1、在每台机器上复制解压出来的flink目录。</p>
<p>2、选择一个作为master节点，然后修改所有机器conf/flink-conf.yaml</p>
<pre><code><code>jobmanager.rpc.address = master主机名</code></pre>
<p>3、修改conf/slaves,将所有work节点写入</p>
<pre><code><code>work01
work02</code></pre>
<p>4、在master上启动集群</p>
<pre><code><code>bin/start-cluster.sh</code></pre>
<h4 id="安装在hadoop">安装在Hadoop</h4>
<p>我们可以选择让Flink运行在Yarn集群上。</p>
<p>下载Flink for Hadoop的包</p>
<p> 保证 HADOOP_HOME已经正确设置即可</p>
<p>启动 bin/yarn-session.sh</p>
<h2 id="运行flink示例程序">运行flink示例程序</h2>
<h4 id="批处理示例">批处理示例：</h4>
<p>提交flink的批处理examples程序：</p>
<pre><code><code>bin/flink run examples/batch/WordCount.jar</code></pre>
<p>这是flink提供的examples下的批处理例子程序，统计单词个数。</p>
<pre><code><code>$ bin/flink run examples/batch/WordCount.jar
Starting execution of program
Executing WordCount example with default input data set.
Use --input to specify file input.
Printing result to stdout. Use --output to specify output path.
(a,5)
(action,1)
(after,1)
(against,1)
(all,2)
(and,12)
(arms,1)
(arrows,1)
(awry,1)
(ay,1)</code></pre>
<p>得到结果，这里统计的是默认的数据集，可以通过--input --output指定输入输出。</p>
<p>我们可以在页面中查看运行的情况：</p>
<p><img src="./images/Flink入门（三）——环境与部署3.png" alt="file" /></p>
<h4 id="流处理示例">流处理示例：</h4>
<p>启动nc服务器：</p>
<pre><code><code>nc -l 9000</code></pre>
<p>提交flink的批处理examples程序：</p>
<pre><code><code>bin/flink run examples/streaming/SocketWindowWordCount.jar --port 9000</code></pre>
<p>这是flink提供的examples下的流处理例子程序，接收socket数据传入，统计单词个数。</p>
<p>在nc端写入单词</p>
<pre><code><code>$ nc -l 9000
lorem ipsum
ipsum ipsum ipsum
bye</code></pre>
<p>输出在日志中</p>
<pre><code><code>$ tail -f log/flink-*-taskexecutor-*.out
lorem : 1
bye : 1
ipsum : 4</code></pre>
<p>停止flink</p>
<pre><code><code>$ ./bin/stop-cluster.sh</code></pre>
<p>在安装好Flink以后，只要快速构建Flink工程，并完成相关代码开发，就可以轻松入手Flink。</p>
<h2 id="构建工具">构建工具</h2>
<p>Flink项目可以使用不同的构建工具进行构建。为了能够快速入门，Flink 为以下构建工具提供了项目模版：</p>
<ul>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.9/zh/dev/projectsetup/java_api_quickstart.html#maven">Maven</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.9/zh/dev/projectsetup/java_api_quickstart.html#gradle">Gradle</a></li>
</ul>
<p>这些模版可以帮助你搭建项目结构并创建初始构建文件。</p>
<h2 id="maven">Maven</h2>
<h3 id="环境要求">环境要求</h3>
<p>唯一的要求是使用 <strong>Maven 3.0.4</strong> （或更高版本）和安装 <strong>Java 8.x</strong>。</p>
<h3 id="创建项目">创建项目</h3>
<p>使用以下命令之一来 <strong>创建项目</strong>：</p>
<p>使用Maven archetypes</p>
<pre><code><code> $ mvn archetype:generate                               \
      -DarchetypeGroupId=org.apache.flink              \
      -DarchetypeArtifactId=flink-quickstart-java      \
      -DarchetypeVersion=1.9.0</code></pre>
<p>运行quickstart脚本</p>
<pre><code><code> curl https://flink.apache.org/q/quickstart.sh | bash -s 1.9.0</code></pre>
<p>下载完成后，查看项目目录结构：</p>
<pre><code><code>tree quickstart/
quickstart/
├── pom.xml
└── src
    └── main
        ├── java
        │   └── org
        │       └── myorg
        │           └── quickstart
        │               ├── BatchJob.java
        │               └── StreamingJob.java
        └── resources
            └── log4j.properties</code></pre>
<p>示例项目是一个 <strong>Maven project</strong>，它包含了两个类：<em>StreamingJob</em> 和 <em>BatchJob</em> 分别是 <em>DataStream</em> and <em>DataSet</em> 程序的基础骨架程序。<br />
<em>main</em> 方法是程序的入口，既可用于IDE测试/执行，也可用于部署。</p>
<p>我们建议你将 <strong>此项目导入IDE</strong> 来开发和测试它。<br />
IntelliJ IDEA 支持 Maven 项目开箱即用。如果你使用的是 Eclipse，使用<a href="http://www.eclipse.org/m2e/">m2e 插件</a> 可以<br />
<a href="http://books.sonatype.com/m2eclipse-book/reference/creating-sect-importing-projects.html#fig-creating-import">导入 Maven 项目</a>。<br />
一些 Eclipse 捆绑包默认包含该插件，其他情况需要你手动安装。</p>
<p><em>请注意</em>：对 Flink 来说，默认的 JVM 堆内存可能太小，你应当手动增加堆内存。<br />
在 Eclipse 中，选择 <code>Run Configurations -&gt; Arguments</code> 并在 <code>VM Arguments</code> 对应的输入框中写入：<code>-Xmx800m</code>。<br />
在 IntelliJ IDEA 中，推荐从菜单 <code>Help | Edit Custom VM Options</code> 来修改 JVM 选项。</p>
<h3 id="构建项目">构建项目</h3>
<p>如果你想要 <strong>构建/打包你的项目</strong>，请在项目目录下运行 ‘<code>mvn clean package</code>’ 命令。命令执行后，你将 <strong>找到一个JAR文件</strong>，里面包含了你的应用程序，以及已作为依赖项添加到应用程序的连接器和库：<code>target/-.jar</code>。</p>
<p><strong>注意：</strong> 如果你使用其他类而不是 <em>StreamingJob</em> 作为应用程序的主类/入口，我们建议你相应地修改 <code>pom.xml</code> 文件中的 <code>mainClass</code> 配置。这样，Flink 可以从 JAR 文件运行应用程序，而无需另外指定主类。</p>
<h2 id="gradle">Gradle</h2>
<h3 id="环境要求-1">环境要求</h3>
<p>唯一的要求是使用 <strong>Gradle 3.x</strong> (或更高版本) 和安装 <strong>Java 8.x</strong> 。</p>
<h3 id="创建项目-1">创建项目</h3>
<p>使用以下命令之一来 <strong>创建项目</strong>：</p>
<p>Gradle示例：</p>
<p>build.gradle</p>
<pre><code><code>buildscript {
    repositories {
        jcenter() // this applies only to the Gradle &#39;Shadow&#39; plugin
    }
    dependencies {
        classpath &#39;com.github.jengelman.gradle.plugins:shadow:2.0.4&#39;
    }
}

plugins {
    id &#39;java&#39;
    id &#39;application&#39;
    // shadow plugin to produce fat JARs
    id &#39;com.github.johnrengelman.shadow&#39; version &#39;2.0.4&#39;
}


// artifact properties
group = &#39;org.myorg.quickstart&#39;
version = &#39;0.1-SNAPSHOT&#39;
mainClassName = &#39;org.myorg.quickstart.StreamingJob&#39;
description = &quot;&quot;&quot;Flink Quickstart Job&quot;&quot;&quot;

ext {
    javaVersion = &#39;1.8&#39;
    flinkVersion = &#39;1.9.0&#39;
    scalaBinaryVersion = &#39;2.11&#39;
    slf4jVersion = &#39;1.7.7&#39;
    log4jVersion = &#39;1.2.17&#39;
}


sourceCompatibility = javaVersion
targetCompatibility = javaVersion
tasks.withType(JavaCompile) {
    options.encoding = &#39;UTF-8&#39;
}

applicationDefaultJvmArgs = [&quot;-Dlog4j.configuration=log4j.properties&quot;]

task wrapper(type: Wrapper) {
    gradleVersion = &#39;3.1&#39;
}

// declare where to find the dependencies of your project
repositories {
    mavenCentral()
    maven { url &quot;https://repository.apache.org/content/repositories/snapshots/&quot; }
}

// 注意：我们不能使用 &quot;compileOnly&quot; 或者 &quot;shadow&quot; 配置，这会使我们无法在 IDE 中或通过使用 &quot;gradle run&quot; 命令运行代码。
// 我们也不能从 shadowJar 中排除传递依赖（请查看 https://github.com/johnrengelman/shadow/issues/159)。
// -&gt; 显式定义我们想要包含在 &quot;flinkShadowJar&quot; 配置中的类库!
configurations {
    flinkShadowJar // dependencies which go into the shadowJar

    // 总是排除这些依赖（也来自传递依赖），因为 Flink 会提供这些依赖。
    flinkShadowJar.exclude group: &#39;org.apache.flink&#39;, module: &#39;force-shading&#39;
    flinkShadowJar.exclude group: &#39;com.google.code.findbugs&#39;, module: &#39;jsr305&#39;
    flinkShadowJar.exclude group: &#39;org.slf4j&#39;
    flinkShadowJar.exclude group: &#39;log4j&#39;
}

// declare the dependencies for your production and test code
dependencies {
    // --------------------------------------------------------------
    // 编译时依赖不应该包含在 shadow jar 中，
    // 这些依赖会在 Flink 的 lib 目录中提供。
    // --------------------------------------------------------------
    compile &quot;org.apache.flink:flink-java:${flinkVersion}&quot;
    compile &quot;org.apache.flink:flink-streaming-java_${scalaBinaryVersion}:${flinkVersion}&quot;

    // --------------------------------------------------------------
    // 应该包含在 shadow jar 中的依赖，例如：连接器。
    // 它们必须在 flinkShadowJar 的配置中！
    // --------------------------------------------------------------
    //flinkShadowJar &quot;org.apache.flink:flink-connector-kafka-0.11_${scalaBinaryVersion}:${flinkVersion}&quot;

    compile &quot;log4j:log4j:${log4jVersion}&quot;
    compile &quot;org.slf4j:slf4j-log4j12:${slf4jVersion}&quot;

    // Add test dependencies here.
    // testCompile &quot;junit:junit:4.12&quot;
}

// make compileOnly dependencies available for tests:
sourceSets {
    main.compileClasspath += configurations.flinkShadowJar
    main.runtimeClasspath += configurations.flinkShadowJar

    test.compileClasspath += configurations.flinkShadowJar
    test.runtimeClasspath += configurations.flinkShadowJar

    javadoc.classpath += configurations.flinkShadowJar
}

run.classpath = sourceSets.main.runtimeClasspath

jar {
    manifest {
        attributes &#39;Built-By&#39;: System.getProperty(&#39;user.name&#39;),
                &#39;Build-Jdk&#39;: System.getProperty(&#39;java.version&#39;)
    }
}

shadowJar {
    configurations = [project.configurations.flinkShadowJar]
}</code></pre>
<p>setting.gradle</p>
<pre><code><code>rootProject.name = &#39;quickstart&#39;</code></pre>
<p>或者运行quickstart脚本</p>
<pre><code><code>    bash -c &quot;$(curl https://flink.apache.org/q/gradle-quickstart.sh)&quot; -- 1.9.0 2.11</code></pre>
<p>查看目录结构：</p>
<pre><code><code>tree quickstart/
quickstart/
├── README
├── build.gradle
├── settings.gradle
└── src
    └── main
        ├── java
        │   └── org
        │       └── myorg
        │           └── quickstart
        │               ├── BatchJob.java
        │               └── StreamingJob.java
        └── resources
            └── log4j.properties</code></pre>
<p>示例项目是一个 <strong>Gradle 项目</strong>，它包含了两个类：<em>StreamingJob</em> 和 <em>BatchJob</em> 是 <em>DataStream</em> 和 <em>DataSet</em> 程序的基础骨架程序。<em>main</em> 方法是程序的入口，即可用于IDE测试/执行，也可用于部署。</p>
<p>我们建议你将 <strong>此项目导入你的 IDE</strong> 来开发和测试它。IntelliJ IDEA 在安装 <code>Gradle</code> 插件后支持 Gradle 项目。Eclipse 则通过 <a href="https://projects.eclipse.org/projects/tools.buildship">Eclipse Buildship</a> 插件支持 Gradle 项目（鉴于 <code>shadow</code> 插件对 Gradle 版本有要求，请确保在导入向导的最后一步指定 Gradle 版本 &gt;= 3.0）。你也可以使用 <a href="https://docs.gradle.org/current/userguide/userguide.html#ide-integration">Gradle’s IDE integration</a> 从 Gradle 创建项目文件。</p>
<h3 id="构建项目-1">构建项目</h3>
<p>如果你想要 <strong>构建/打包项目</strong>，请在项目目录下运行 ‘<code>gradle clean shadowJar</code>’ 命令。命令执行后，你将 <strong>找到一个 JAR 文件</strong>，里面包含了你的应用程序，以及已作为依赖项添加到应用程序的连接器和库：<code>build/libs/--all.jar</code>。</p>
<p><strong>注意：</strong> 如果你使用其他类而不是 <em>StreamingJob</em> 作为应用程序的主类/入口，我们建议你相应地修改 <code>build.gradle</code> 文件中的 <code>mainClassName</code> 配置。这样，Flink 可以从 JAR 文件运行应用程序，而无需另外指定主类。</p>
<p>Flink系列文章：</p>
<p><a href="https://mp.weixin.qq.com/s/m4GofU2fnsuSyP5lIyBpOQ">Flink入门（一）——Apache Flink介绍</a><br />
<a href="https://mp.weixin.qq.com/s/XNfC9w1i_F_7r6qHL7wyAg">Flink入门（二）——Flink架构介绍</a></p>
<p>更多实时计算,Flink,Kafka等相关技术博文，欢迎关注实时流式计算</p>
<p><img src="./images/Flink入门（三）——环境与部署4.png" alt="file" /></p>

</div>
</div><hr><script charset='utf-8' src='../../js/sming.js'></script></body></html>