<html><head><meta charset='utf-8'><meta name='viewport' content='width=device-width, initial-scale=1'>
<meta name='applicable-device' content='pc'><meta name='keywords' content='电脑,电脑讲解,电脑技术,编程,电脑故障维修小白学 Python 爬虫（24）：2019 豆瓣电影排行' />
<script src='../../highlight/highlight.pack.js'></script>
<link rel='stylesheet' type='text/css' href='../../highlight/styles/monokai.css'/>

<link rel='stylesheet' href='../../fenxiang/dist/css/share.min.css'>
<script src='../../fenxiang/src/js/social-share.js'></script>
<script src='../../fenxiang/src/js/qrcode.js'></script>

</head><body><script>hljs.initHighlightingOnLoad();</script><script>
var system ={};  
var p = navigator.platform;       
system.win = p.indexOf('Win') == 0;  
system.mac = p.indexOf('Mac') == 0;  
system.x11 = (p == 'X11') || (p.indexOf('Linux') == 0);     
if(system.win||system.mac||system.xll){
document.write("<link href='../css/3.css' rel='stylesheet' type='text/css'>");}else{ document.write("<link href='../css/3wap.css' rel='stylesheet' type='text/css'>");}</script><script src='../../js/3.js'></script><div class='div2'><div class='heading_nav'><ul><div><li><a href='../../index.html'>首页</a></li>
</div><div onclick='hidden1()' >分享</div>
</ul></div></div>
<div id='heading_nav2'> 
<li class='row' >
<div class='social-share' data-mode='prepend'><a href='javascript:' class='social-share-icon icon-heart'></a></div></li></div><script charset='utf-8' src='../../3/js/hengfu.js'></script><script charset='utf-8' src='../../3/js/hengfu2.js'></script><hr><div class='div1'><div class='biaoti'><center>小白学 Python 爬虫（24）：2019 豆瓣电影排行</center></div><div class='banquan'>原文出处:本文由博客园博主极客挖掘机提供。<br/>
原文连接:https://www.cnblogs.com/babycomeon/p/12081996.html</div><br>
    <p><img src="./images/小白学 Python 爬虫（24）：2019 豆瓣电影排行0.png" /></p>
<blockquote>
<p>人生苦短，我用 Python</p>
</blockquote>
<p>前文传送门：</p>
<p><a href="https://www.geekdigging.com/2019/11/13/3303836941/">小白学 Python 爬虫（1）：开篇</a></p>
<p><a href="https://www.geekdigging.com/2019/11/20/2586166930/">小白学 Python 爬虫（2）：前置准备（一）基本类库的安装</a></p>
<p><a href="https://www.geekdigging.com/2019/11/21/1005563697/">小白学 Python 爬虫（3）：前置准备（二）Linux基础入门</a></p>
<p><a href="https://www.geekdigging.com/2019/11/22/3679472340/">小白学 Python 爬虫（4）：前置准备（三）Docker基础入门</a></p>
<p><a href="https://www.geekdigging.com/2019/11/24/334078215/">小白学 Python 爬虫（5）：前置准备（四）数据库基础</a></p>
<p><a href="https://www.geekdigging.com/2019/11/25/1881661601/">小白学 Python 爬虫（6）：前置准备（五）爬虫框架的安装</a></p>
<p><a href="https://www.geekdigging.com/2019/11/26/1197821400/">小白学 Python 爬虫（7）：HTTP 基础</a></p>
<p><a href="https://www.geekdigging.com/2019/11/27/101847406/">小白学 Python 爬虫（8）：网页基础</a></p>
<p><a href="https://www.geekdigging.com/2019/11/28/1668465912/">小白学 Python 爬虫（9）：爬虫基础</a></p>
<p><a href="https://www.geekdigging.com/2019/12/01/2475257648/">小白学 Python 爬虫（10）：Session 和 Cookies</a></p>
<p><a href="https://www.geekdigging.com/2019/12/02/2333822325/">小白学 Python 爬虫（11）：urllib 基础使用（一）</a></p>
<p><a href="https://www.geekdigging.com/2019/12/03/819896244/">小白学 Python 爬虫（12）：urllib 基础使用（二）</a></p>
<p><a href="https://www.geekdigging.com/2019/12/04/2992515886/">小白学 Python 爬虫（13）：urllib 基础使用（三）</a></p>
<p><a href="https://www.geekdigging.com/2019/12/05/104488944/">小白学 Python 爬虫（14）：urllib 基础使用（四）</a></p>
<p><a href="https://www.geekdigging.com/2019/12/07/2788855167/">小白学 Python 爬虫（15）：urllib 基础使用（五）</a></p>
<p><a href="https://www.geekdigging.com/2019/12/09/1691033431/">小白学 Python 爬虫（16）：urllib 实战之爬取妹子图</a></p>
<p><a href="https://www.geekdigging.com/2019/12/10/1910005577/">小白学 Python 爬虫（17）：Requests 基础使用</a></p>
<p><a href="https://www.geekdigging.com/2019/12/11/1468953802/">小白学 Python 爬虫（18）：Requests 进阶操作</a></p>
<p><a href="https://www.geekdigging.com/2019/12/12/3568648672/">小白学 Python 爬虫（19）：Xpath 基操</a></p>
<p><a href="https://www.geekdigging.com/2019/12/13/2569867940/">小白学 Python 爬虫（20）：Xpath 进阶</a></p>
<p><a href="https://www.geekdigging.com/2019/12/15/2789385418/">小白学 Python 爬虫（21）：解析库 Beautiful Soup（上）</a></p>
<p><a href="https://www.geekdigging.com/2019/12/16/876770087/">小白学 Python 爬虫（22）：解析库 Beautiful Soup（下）</a></p>
<p><a href="https://www.geekdigging.com/2019/12/17/876770088/">小白学 Python 爬虫（23）：解析库 pyquery 入门</a></p>
<h2 id="引言">引言</h2>
<p>从本篇的标题各位同学应该已经猜到了，本篇又到了实战环节~~~</p>
<p>2019 已经快过完了，按照本文推送的时间预估，到 2020 应该还有十来天的时间，又到了各个公司出各种 2019 榜单的时间，小编这里呢，就先帮豆瓣搞一个 2019 电影评分排行榜，希望豆瓣官方看到不要打我。</p>
<p><strong>郑重声明：</strong> 本文仅限用作学习等目的。</p>
<h2 id="分析">分析</h2>
<p>还是先看一下我们要爬取的页面：</p>
<p><img src="./images/小白学 Python 爬虫（24）：2019 豆瓣电影排行1.png" /></p>
<p>链接：</p>
<pre><code><code>https://movie.douban.com/explore#!type=movie&amp;tag=%E7%83%AD%E9%97%A8&amp;sort=time&amp;page_limit=20&amp;page_start=0</code></pre>
<p>思维敏捷的同学看着上面这个链接可能就已经发现了什么，对的，这个链接上已经有分页信息了。</p>
<p><code>page_limit</code> 应该是一页的元素， <code>page_start</code> 应该是这一页开始的一个序号。</p>
<p>我们往下翻一下页面，看看下面有没有下一页之类的按钮，翻几页看下地址栏的变化是否和我们推测的一致。</p>
<p><img src="./images/小白学 Python 爬虫（24）：2019 豆瓣电影排行2.png" /></p>
<p>emmmmmmmmm</p>
<p>小编猜错了，这里不是下一页，是加载更多，不过问题不大，一个意思，先点一下我们看下地址栏：</p>
<pre><code><code>https://movie.douban.com/explore#!type=movie&amp;tag=%E7%83%AD%E9%97%A8&amp;sort=time&amp;page_limit=20&amp;page_start=20</code></pre>
<p>和前面一个地址作对比可以发现，只有最后的 <code>page_start</code> 参数有变化，说明我们刚才上面的猜测没有问题。</p>
<p>加载更多多点几次，可以发现，这里的电影是可以一直往后排的，可以加载到 2018 年的数据：</p>
<p><img src="./images/小白学 Python 爬虫（24）：2019 豆瓣电影排行3.png" /></p>
<p>emmmmmmmmm，有点尴尬，这个数据竟然手动翻出来了，理论上是应该程序自己判断的。</p>
<p>这里的悬浮层上已经显示了我们想要的数据，接下来的问题是，我们如何获得这个悬浮层上的数据，直接从 DOM 节点来取可以么？</p>
<p>显然是不行的，不信可以自己动手试试，每个电影的悬浮层其实都是同一个 DOM 节点，只是里面填充的数据不同，显然这个 DOM 节点中的数据是鼠标挪上去的时候才动态加载出来的。</p>
<p>那么我们从哪里能看到加载数据的来源呢？</p>
<p>如果上一篇实战有仔细看实操过的同学应该已经想到了， Chrome 浏览器开发者模式中的 Network 标签。</p>
<p>没错，就是这里，我们看一下：</p>
<p><img src="./images/小白学 Python 爬虫（24）：2019 豆瓣电影排行4.png" /></p>
<p>首先选择 Network 标签，然后在下面的标签上选择 XHR 。然后鼠标在不同的电影上移动，可以看到鼠标每次移到一张图片上，就会有一个请求，我们看一下这个请求的响应信息：</p>
<pre><code><code>{&quot;r&quot;:0,&quot;subject&quot;:{&quot;episodes_count&quot;:&quot;&quot;,&quot;star&quot;:&quot;40&quot;,&quot;blacklisted&quot;:&quot;available&quot;,&quot;title&quot;:&quot;我身体里的那个家伙 내안의 그놈‎ (2019)&quot;,&quot;url&quot;:&quot;https:\/\/movie.douban.com\/subject\/27088750\/&quot;,&quot;collection_status&quot;:&quot;&quot;,&quot;rate&quot;:&quot;7.2&quot;,&quot;short_comment&quot;:{&quot;content&quot;:&quot;男主真的他妈帅 但是我真的接受不了和罗美兰打k &quot;,&quot;author&quot;:&quot;SOUL&quot;},&quot;is_tv&quot;:false,&quot;subtype&quot;:&quot;Movie&quot;,&quot;directors&quot;:[&quot;姜孝镇&quot;],&quot;actors&quot;:[&quot;郑振永&quot;,&quot;朴圣雄&quot;,&quot;罗美兰&quot;,&quot;李垂珉&quot;,&quot;李俊赫&quot;,&quot;金光奎&quot;,&quot;闵智雅&quot;,&quot;尹敬浩&quot;,&quot;金贤穆&quot;,&quot;朴庆惠&quot;,&quot;赵贤荣&quot;,&quot;尹颂雅&quot;,&quot;智燦&quot;,&quot;金凡振 &quot;,&quot;郑元昌&quot;,&quot;孙光业&quot;,&quot;黄仁俊&quot;,&quot;Dae-han Kim&quot;],&quot;duration&quot;:&quot;122分钟&quot;,&quot;region&quot;:&quot;韩国&quot;,&quot;playable&quot;:false,&quot;id&quot;:&quot;27088750&quot;,&quot;types&quot;:[&quot;剧情&quot;,&quot;喜剧&quot;],&quot;release_year&quot;:&quot;2019&quot;}}</code></pre>
<p>那么我们剩下要关心的就是这个请求的地址了，先看下这个请求的地址：</p>
<pre><code><code>https://movie.douban.com/j/subject_abstract?subject_id=27088750</code></pre>
<p>这里看起来好像只有最后一个 <code>subject_id</code> 参数是变化的，其他的都是定死的，多看几个请求检验下我们的推测，小编这里就不检验了，免得嫌弃说小编水内容。</p>
<p>还有一个问题，最后这个 <code>subject_id</code> 的数据从哪里来，好像没见过的，小编凭借自己多年丰富的开发经验，猜测这个数据应该是在页面的上的。我们接着看下这个电影的页面 DOM 结构。</p>
<p><img src="./images/小白学 Python 爬虫（24）：2019 豆瓣电影排行5.png" /></p>
<p>看到了没，这里的数据是来源于 DOM 结构上的 <code>data-id</code> 属性。</p>
<p>PS：更新一件事情，一件异常尴尬的事情，小编偶然发现，点击加载更多的时候，实际上是对应了一个 API 接口，这个接口的访问地址如下：</p>
<pre><code><code>https://movie.douban.com/j/search_subjects?type=movie&amp;tag=%E7%83%AD%E9%97%A8&amp;sort=time&amp;page_limit=20&amp;page_start=20</code></pre>
<p>这个在 NetWork 中有看到，如下图：</p>
<p><img src="./images/小白学 Python 爬虫（24）：2019 豆瓣电影排行6.png" /></p>
<p>从图中可以看到，这里直接返回了 JSON 数据，并且这个 JSON 数据返回后，顺便还修改了地址栏的数据。</p>
<p>这里得到的数据如下：</p>
<pre><code><code>{
    &quot;subjects&quot;:[
        {
            &quot;rate&quot;:&quot;6.7&quot;,
            &quot;cover_x&quot;:1382,
            &quot;title&quot;:&quot;在无爱之森呐喊&quot;,
            &quot;url&quot;:&quot;https://movie.douban.com/subject/30337760/&quot;,
            &quot;playable&quot;:false,
            &quot;cover&quot;:&quot;https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2571542101.jpg&quot;,
            &quot;id&quot;:&quot;30337760&quot;,
            &quot;cover_y&quot;:2048,
            &quot;is_new&quot;:false
        }
    ]
}</code></pre>
<p>因为整体数据有 20 条，太长了放不下，小编这里仅保留了一条数据。</p>
<h2 id="编码">编码</h2>
<p>有了上面的分析，其实写代码就已经很简单了，我们所有需要用到的数据都可以直接从 API 接口中直接获取到 JSON 的数据。</p>
<p>屡一下思路，首先我们从</p>
<pre><code><code>https://movie.douban.com/j/search_subjects?type=movie&amp;tag=%E7%83%AD%E9%97%A8&amp;sort=time&amp;page_limit=20&amp;page_start=0</code></pre>
<p>这个链接中直接获取电影的相关数据，这里对我们有用的数据是 <code>id</code> ，获取到这个 <code>id</code> 后，再从</p>
<pre><code><code>https://movie.douban.com/j/subject_abstract?subject_id=27088750</code></pre>
<p>这个链接中获取到电影的详情数据，用上面得到的 <code>id</code> 替换这里的 <code>subject_id</code> 。</p>
<p>好像没页面 DOM 解析啥事儿了，哎，真的是一次失败的选题，下次再也不选豆瓣了。</p>
<p>代码内容有些简单，小编直接贴出来吧，数据还是在 Mysql 中开了一张表做存放：</p>
<pre><code><code>import requests
import pymysql

# 数据库连接
def connect():
    conn = pymysql.connect(host=&#39;localhost&#39;,
                           port=3306,
                           user=&#39;root&#39;,
                           password=&#39;password&#39;,
                           database=&#39;test&#39;,
                           charset=&#39;utf8mb4&#39;)

    # 获取操作游标
    cursor = conn.cursor()
    return {&quot;conn&quot;: conn, &quot;cursor&quot;: cursor}

connection = connect()
conn, cursor = connection[&#39;conn&#39;], connection[&#39;cursor&#39;]

sql_insert = &quot;insert into douban2019(id, title, rate, short_comment, duration, subtype, region, release_year, create_date) values (%(id)s, %(title)s, %(rate)s, %(short_comment)s, %(duration)s, %(subtype)s, %(region)s, %(release_year)s, now())&quot;

headers = {
    &#39;User-Agent&#39;: &#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36&#39;
}

flag = True

def get_movie_list(page_start):
    r = requests.get(&#39;https://movie.douban.com/j/search_subjects?type=movie&amp;tag=%E7%83%AD%E9%97%A8&amp;sort=time&amp;page_limit=20&amp;page_start=&#39; + str(page_start), headers = headers)
    for item in r.json()[&#39;subjects&#39;]:
        get_movie_info(item[&#39;id&#39;])

def get_movie_info(subject_id):
    r = requests.get(&#39;https://movie.douban.com/j/subject_abstract?subject_id=&#39; + str(subject_id), headers=headers)

    subject = r.json()[&#39;subject&#39;]

    if subject[&#39;release_year&#39;] != &#39;2019&#39;:
        global flag
        flag = False
        return

    print(subject)

    insert_data = {
        &quot;id&quot;: subject[&#39;id&#39;],
        &quot;title&quot;: subject[&#39;title&#39;],
        &quot;rate&quot;: subject[&#39;rate&#39;],
        &quot;short_comment&quot;: subject[&#39;short_comment&#39;][&#39;content&#39;],
        &quot;duration&quot;: subject[&#39;duration&#39;],
        &quot;subtype&quot;: subject[&#39;subtype&#39;],
        &quot;region&quot;: subject[&#39;region&#39;],
        &quot;release_year&quot;: subject[&#39;release_year&#39;]
    }
    cursor.execute(sql_insert, insert_data)
    conn.commit()
    print(subject[&#39;title&#39;], &#39;写入完成&#39;)



def main():
    num = 0
    while(flag):
        get_movie_list(num)
        num += 20

if __name__ == &#39;__main__&#39;:
    main()</code></pre>
<h2 id="小结">小结</h2>
<p>最后小编做了一下简单的统计，截止目前， 2019 豆瓣电影共计 312 部，评分超过 8.0 分的共计 37 部，超过 8.5 分的共计 14 部，超过 9.0 分的只有 1 部。</p>
<p>下表为评分超过 8.0 分的，还有没看过的小伙伴可以抓紧时间看一下咯~~</p>
<table>
<thead>
<tr class="header">
<th>名称</th>
<th>评分</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>爱尔兰人 The Irishman‎ (2019)</td>
<td>9.1</td>
</tr>
<tr class="even">
<td>银河英雄传说 Die Neue These 星乱 第1章 銀河英雄伝説 Die Neue These 星乱 第1章‎ (2019)</td>
<td>8.9</td>
</tr>
<tr class="odd">
<td>小丑 Joker‎ (2019)</td>
<td>8.8</td>
</tr>
<tr class="even">
<td>婚姻故事 Marriage Story‎ (2019)</td>
<td>8.8</td>
</tr>
<tr class="odd">
<td>玩具总动员4 Toy Story 4‎ (2019)</td>
<td>8.7</td>
</tr>
<tr class="even">
<td>寄生虫 기생충‎ (2019)</td>
<td>8.7</td>
</tr>
<tr class="odd">
<td>代号基亚斯：复活的鲁路修 コードギアス 復活のルルーシュ‎ (2019)</td>
<td>8.7</td>
</tr>
<tr class="even">
<td>82年生的金智英 82년생 김지영‎ (2019)</td>
<td>8.7</td>
</tr>
<tr class="odd">
<td>克劳斯：圣诞节的秘密 Klaus‎ (2019)</td>
<td>8.6</td>
</tr>
<tr class="even">
<td>痛苦与荣耀 Dolor y gloria‎ (2019)</td>
<td>8.6</td>
</tr>
<tr class="odd">
<td>青春期猪头少年不做怀梦少女的梦 青春ブタ野郎はゆめみる少女の夢を見ない‎ (2019)</td>
<td>8.6</td>
</tr>
<tr class="even">
<td>复仇者联盟4：终局之战 Avengers: Endgame‎ (2019)</td>
<td>8.5</td>
</tr>
<tr class="odd">
<td>哪吒之魔童降世‎ (2019)</td>
<td>8.5</td>
</tr>
<tr class="even">
<td>普罗米亚 プロメア‎ (2019)</td>
<td>8.5</td>
</tr>
<tr class="odd">
<td>少年的你‎ (2019)</td>
<td>8.4</td>
</tr>
<tr class="even">
<td>少年泰坦出击大战少年泰坦 Teen Titans Go! vs Teen Titans‎ (2019)</td>
<td>8.4</td>
</tr>
<tr class="odd">
<td>悲惨世界 Les misérables‎ (2019)</td>
<td>8.4</td>
</tr>
<tr class="even">
<td>我的一级兄弟 나의 특별한 형제‎ (2019)</td>
<td>8.3</td>
</tr>
<tr class="odd">
<td>燃烧女子的肖像 Portrait de la jeune fille en feu‎ (2019)</td>
<td>8.3</td>
</tr>
<tr class="even">
<td>再见钟情 Mon inconnue‎ (2019)</td>
<td>8.3</td>
</tr>
<tr class="odd">
<td>我在雨中等你 The Art of Racing in the Rain‎ (2019)</td>
<td>8.2</td>
</tr>
<tr class="even">
<td>罗小黑战记‎ (2019)</td>
<td>8.2</td>
</tr>
<tr class="odd">
<td>行骗天下JP：浪漫篇 コンフィデンスマンJP‎ (2019)</td>
<td>8.2</td>
</tr>
<tr class="even">
<td>阿松 剧场版 劇場版 えいがのおそ松さん‎ (2019)</td>
<td>8.2</td>
</tr>
<tr class="odd">
<td>蜡笔小新：新婚旅行飓风之遗失的野原广志 映画クレヨンしんちゃん 新婚旅行ハリケーン ～失われたひろし～‎ (2019)</td>
<td>8.2</td>
</tr>
<tr class="even">
<td>驭风男孩 The Boy Who Harnessed the Wind‎ (2019)</td>
<td>8.1</td>
</tr>
<tr class="odd">
<td>对不起，我们错过了你 Sorry We Missed You‎ (2019)</td>
<td>8.1</td>
</tr>
<tr class="even">
<td>续命之徒：绝命毒师电影 El Camino: A Breaking Bad Movie‎ (2019)</td>
<td>8.1</td>
</tr>
<tr class="odd">
<td>我失去了身体 J'ai perdu mon corps‎ (2019)</td>
<td>8.1</td>
</tr>
<tr class="even">
<td>最初的梦想 Chhichhore‎ (2019)</td>
<td>8.1</td>
</tr>
<tr class="odd">
<td>千子2 センコロール コネクト‎ (2019)</td>
<td>8.0</td>
</tr>
<tr class="even">
<td>地久天长‎ (2019)</td>
<td>8.0</td>
</tr>
<tr class="odd">
<td>金发男子 Un rubio‎ (2019)</td>
<td>8.0</td>
</tr>
<tr class="even">
<td>心理测量者SS2：第一卫士 PSYCHO-PASS サイコパス Sinners of the System Case.2「First Guardian」‎ (2019)</td>
<td>8.0</td>
</tr>
<tr class="odd">
<td>漫长的告别 長いお別れ‎ (2019)</td>
<td>8.0</td>
</tr>
<tr class="even">
<td>我的喜马拉雅‎ (2019)</td>
<td>8.0</td>
</tr>
<tr class="odd">
<td>小委托人 어린 의뢰인‎ (2019)</td>
<td>8.0</td>
</tr>
</tbody>
</table>
<h2 id="示例代码">示例代码</h2>
<p>本系列的所有代码小编都会放在代码管理仓库 Github 和 Gitee 上，方便大家取用。</p>
<p><a href="https://github.com/meteor1993/python-learning/tree/master/python-spider/douban-2019" title="示例代码-Github">示例代码-Github</a></p>
<p><a href="https://gitee.com/inwsy/python-learning/tree/master/python-spider/douban-2019" title="示例代码-Gitee">示例代码-Gitee</a></p>

</div>
</div><hr><script charset='utf-8' src='../../js/sming.js'></script></body></html>